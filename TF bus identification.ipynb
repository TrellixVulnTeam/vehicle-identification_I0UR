{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF bus identification.ipynb","provenance":[{"file_id":"1c8nptQvVA9v42v0gsjjc4bekd2s-fi1x","timestamp":1588133044222},{"file_id":"https://github.com/dctian/DeepPiCar/blob/master/models/object_detection/code/tensorflow_traffic_sign_detection.ipynb","timestamp":1587548201036}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uQCnYPVDrsgx","colab_type":"text"},"source":["Based on:\n","\n","https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/\n","\n","https://towardsdatascience.com/deeppicar-part-6-963334b2abe0\n","\n","\n","Pretrained Model from (Tensorflow detection model zoo):\n","\n","https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"]},{"cell_type":"markdown","metadata":{"id":"IOKeb3tRElm7","colab_type":"text"},"source":["# Section 0: Actions done before running this notebook\n","1- Took around 300 photos of cars with lables\n","\n","2- Run script to scale images dimentions to 800x600 and Divide images to 80% train, 10% test, 10% validation\n","\n","3- Use [labelImg](https://github.com/tzutalin/labelImg) for annotating \"plate no\" and \"bus run\" objects on each of train & test images"]},{"cell_type":"code","metadata":{"id":"MVrVzjhp6Tnz","colab_type":"code","outputId":"7bfb61e2-179a-4ccc-e2bc-55b698259bae","executionInfo":{"status":"ok","timestamp":1588204304662,"user_tz":-600,"elapsed":7404,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# These versions required to work with the scripts available in https://github.com/tensorflow/models/tree/master/research/object_detection\n","# for transfer learning\n","!pip install numpy==1.17.4\n","%tensorflow_version 1.x\n","!pip install --user gast==0.2.2"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.6/dist-packages (1.17.4)\n","TensorFlow 1.x selected.\n","Requirement already satisfied: gast==0.2.2 in /root/.local/lib/python3.6/site-packages (0.2.2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"etOThFKokSmU","colab_type":"text"},"source":["# Section 1: Mount Google drive\n","Mount my Google Drive to save modeling output files there, so that it won't be wiped out when colab Virtual Machine restarts."]},{"cell_type":"code","metadata":{"id":"eCjkgwJA-Zyx","colab_type":"code","outputId":"c25a33b3-77d5-4bfe-cca9-d46c77df5a22","executionInfo":{"status":"ok","timestamp":1588204349807,"user_tz":-600,"elapsed":41051,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","model_dir = '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource'\n","#!rm -rf '{model_dir}'\n","os.makedirs(model_dir, exist_ok=True)\n","!ls -ltra '{model_dir}'/.."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","total 72\n","drwx------ 2 root root  4096 Mar  5 23:36  Papers\n","drwx------ 2 root root  4096 Mar  6 03:31  LevelCrossingRemovalProject\n","drwx------ 2 root root  4096 Mar 25 04:14  Trial\n","-rw------- 1 root root  3414 Apr 15 08:08  ghawadykey\n","-rw------- 1 root root   762 Apr 21 06:50  ghawadykey.pub\n","drwx------ 2 root root  4096 Apr 22 07:51  SampleClicks\n","-rw------- 1 root root 20284 Apr 22 07:53 'Bus Run Label.docx'\n","drwx------ 2 root root  4096 Apr 22 07:55  FinalSource\n","-rw------- 1 root root 28124 Apr 29 13:26 'R&D Tax Concession LXRP.docx'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yhzxsJb3dpWq","colab_type":"text"},"source":["# Section 2: Configs and Hyperparameters\n","\n","Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."]},{"cell_type":"code","metadata":{"id":"iLtZc41d-rrI","colab_type":"code","colab":{}},"source":["# Number of training steps\n","num_steps = 5000  # 200000\n","\n","# Number of evaluation steps\n","num_eval_steps = 50\n","\n","\n","# model name and configs are from Model Zoo github: \n","# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models\n","# https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs\n","MODELS_CONFIG = {\n","    'ssdlite_mobilenet_v2': {\n","        'model_name': 'ssdlite_mobilenet_v2_coco_2018_05_09',\n","        'pipeline_file': 'ssdlite_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'ssd_mobilenet_v2_quantized': {\n","        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03',\n","        'pipeline_file': 'ssd_mobilenet_v2_quantized_300x300_coco.config',\n","        'batch_size': 12\n","    },\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_small_coco_2020_01_14.tar.gz\n","    'ssd_mobilenet_v3_small_coco': {\n","        'model_name': 'ssd_mobilenet_v3_small_coco_2020_01_14',\n","        'pipeline_file': 'ssdlite_mobilenet_v3_small_320x320_coco.config',\n","        'batch_size': 12\n","    },\n","    #https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config\n","    #http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz\n","    'ssd_mobilenet_v3_large_coco': {\n","        'model_name': 'ssd_mobilenet_v3_large_coco_2020_01_14',\n","        'pipeline_file': 'ssdlite_mobilenet_v3_large_320x320_coco.config',\n","        'batch_size': 12\n","    },\n","    #https://storage.cloud.google.com/mobilenet_edgetpu/checkpoints/ssdlite_mobilenet_edgetpu_coco_quant.tar.gz\n","    'ssdlite_mobilenet_edgetpu_coco_quant': {\n","        'model_name': 'ssdlite_mobilenet_edgetpu_coco_quant',\n","        'pipeline_file': 'ssdlite_mobilenet_edgetpu_320x320_coco_quant.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 12\n","    }\n","}\n","\n","# Select a model in MODELS_CONFIG\n","# Note: Must be a quantized model, which reduces the model size significantly for mobile/edge use\n","selected_model = 'ssd_mobilenet_v2_quantized'\n","#selected_model = 'ssd_mobilenet_v3_large_coco'  # used 15K training steps to get better results\n","#selected_model = 'ssd_mobilenet_v3_small_coco'  # didn't give good results\n","#selected_model = 'ssdlite_mobilenet_v2'  # the False Positives for plate numbers were almost in every images\n","\n","# Name of the object detection model to use.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Name of the pipline file in tensorflow object detection API.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rw-YqZHUKv-Y","colab_type":"text"},"source":["# Section 3: Set up Training Environment"]},{"cell_type":"code","metadata":{"id":"2Bh7-Xo6JUFt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"7b6a55a7-74cf-4046-b582-0d1808094e0c","executionInfo":{"status":"ok","timestamp":1588206281625,"user_tz":-600,"elapsed":1350,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}}},"source":["# Where the new trained model will be saved\n","from datetime import datetime\n","curdate = datetime.now().strftime(\"%Y_%m_%d\")\n","\n","trainedmodel_dir = os.path.join(model_dir, 'trainedmodel', selected_model, curdate)\n","os.makedirs(trainedmodel_dir, exist_ok = True)\n","\n","print(trainedmodel_dir)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v2_quantized/2020_04_30\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bI8__uNS8-ns","colab_type":"text"},"source":["## Install required packages"]},{"cell_type":"code","metadata":{"id":"sMyfqlDB_TA2","colab_type":"code","outputId":"f6da4b3b-5496-4313-e0fe-60e6417b8aa7","executionInfo":{"status":"ok","timestamp":1588168002566,"user_tz":-600,"elapsed":15141,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["%cd '{model_dir}'\n","#!git clone --quiet https://github.com/tensorflow/models.git\n","print('installing protobuf')\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","print('installing Cython')\n","!pip install -q Cython contextlib2 pillow lxml matplotlib\n","print('installing pycocotools')\n","!pip install -q pycocotools\n","print('run protoc')\n","%cd '{model_dir}/models/research'\n","!protoc object_detection/protos/*.proto --python_out=.\n","print('setting environment variable')\n","import os\n","os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/:/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/slim/'\n","\n","print('run model_builder_test')\n","# To verify all dependencies are successfull installed\n","#!python object_detection/builders/model_builder_test.py"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource\n","installing protobuf\n","installing Cython\n","installing pycocotools\n","run protoc\n","/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research\n","setting environment variable\n","run model_builder_test\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u-k7uGThXlny","colab_type":"text"},"source":["## Prepare `tfrecord` files\n","\n","Use the following scripts to generate the `tfrecord` files which is used for model training and evaluation."]},{"cell_type":"code","metadata":{"id":"ezGDABRXXhPP","colab_type":"code","outputId":"ec559f52-46e2-498a-fa64-320bdcdb8714","executionInfo":{"status":"ok","timestamp":1588168289599,"user_tz":-600,"elapsed":289428,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":547}},"source":["%cd {model_dir}\n","print(\"train_cars xml_to_csv\")\n","# Convert train folder annotation xml files to a single csv file,\n","# generate the `label_map.pbtxt` file to `data/` directory as well.\n","!python code/xml_to_csv.py -i Data/train_cars -o Data/annotations/train_labels.csv -l Data/annotations\n","print(\"test_cars xml_to_csv\")\n","# Convert test folder annotation xml files to a single csv.\n","!python code/xml_to_csv.py -i Data/test_cars -o Data/annotations/test_labels.csv\n","\n","print(\"train_labels generate_tfrecord\")\n","# Generate `train.record`\n","!python code/generate_tfrecord.py --csv_input=Data/annotations/train_labels.csv --output_path=Data/annotations/train.record --img_path=Data/train_cars --label_map Data/annotations/label_map.pbtxt\n","print(\"test_labels generate_tfrecord\")\n","# Generate `test.record`\n","!python code/generate_tfrecord.py --csv_input=Data/annotations/test_labels.csv --output_path=Data/annotations/test.record --img_path=Data/test_cars --label_map Data/annotations/label_map.pbtxt"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource\n","train_cars xml_to_csv\n","Successfully converted xml to csv.\n","Generate `Data/annotations/label_map.pbtxt`\n","test_cars xml_to_csv\n","Successfully converted xml to csv.\n","train_labels generate_tfrecord\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0429 13:49:09.578909 140207477233536 module_wrapper.py:139] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 13:49:10.714112 140207477233536 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/annotations/train.record\n","test_labels generate_tfrecord\n","WARNING:tensorflow:From code/generate_tfrecord.py:134: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0429 13:51:12.708905 139934040639360 module_wrapper.py:139] From code/generate_tfrecord.py:107: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 13:51:13.313410 139934040639360 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Successfully created the TFRecords: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/annotations/test.record\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tgd-fzAIkZlV","colab_type":"code","colab":{}},"source":["test_record_fname = model_dir + '/Data/annotations/test.record'\n","train_record_fname = model_dir + '/Data/annotations/train.record'\n","label_map_pbtxt_fname = model_dir + '/Data/annotations/label_map.pbtxt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZ8otnfyCYdG","colab_type":"code","outputId":"b63a0b60-3eeb-449a-d53b-a45bfe2b33d6","executionInfo":{"status":"ok","timestamp":1588168293301,"user_tz":-600,"elapsed":239716,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["!cat Data/annotations/test_labels.csv"],"execution_count":10,"outputs":[{"output_type":"stream","text":["filename,width,height,class,xmin,ymin,xmax,ymax\n","1.jpg,800,600,BusRun,507,193,593,221\n","1.jpg,800,600,PlateNo,283,460,468,528\n","2.jpg,800,600,PlateNo,289,494,457,548\n","2.jpg,800,600,BusRun,482,228,555,249\n","3.jpg,800,600,PlateNo,213,430,389,490\n","3.jpg,800,600,BusRun,426,150,504,173\n","4.jpg,800,600,PlateNo,281,445,459,542\n","4.jpg,800,600,BusRun,349,148,418,167\n","5.jpg,800,600,PlateNo,273,415,412,472\n","5.jpg,800,600,BusRun,459,164,532,189\n","6.jpg,800,600,PlateNo,306,381,487,436\n","6.jpg,800,600,BusRun,518,149,597,175\n","7.jpg,800,600,PlateNo,279,419,428,461\n","7.jpg,800,600,BusRun,450,156,522,179\n","8.jpg,800,600,PlateNo,300,433,459,472\n","8.jpg,800,600,BusRun,467,214,528,234\n","9.jpg,800,600,PlateNo,358,401,533,446\n","9.jpg,800,600,BusRun,285,122,360,143\n","10.jpg,800,600,PlateNo,248,471,417,529\n","10.jpg,800,600,BusRun,451,198,530,222\n","11.jpg,800,600,PlateNo,302,396,463,455\n","11.jpg,800,600,BusRun,248,178,311,204\n","12.jpg,800,600,PlateNo,305,467,475,514\n","12.jpg,800,600,BusRun,533,193,609,219\n","13.jpg,800,600,PlateNo,223,466,381,519\n","13.jpg,800,600,BusRun,421,212,496,236\n","14.jpg,800,600,PlateNo,313,450,495,488\n","14.jpg,800,600,BusRun,528,197,612,226\n","15.jpg,800,600,PlateNo,295,403,467,471\n","15.jpg,800,600,BusRun,536,178,622,213\n","16.jpg,800,600,PlateNo,296,422,478,469\n","16.jpg,800,600,BusRun,186,110,263,131\n","17.jpg,800,600,PlateNo,229,481,455,534\n","17.jpg,800,600,BusRun,463,104,564,132\n","18.jpg,800,600,PlateNo,211,468,393,560\n","18.jpg,800,600,BusRun,482,185,576,213\n","19.jpg,800,600,PlateNo,346,416,504,464\n","19.jpg,800,600,BusRun,255,209,328,232\n","20.jpg,800,600,PlateNo,290,423,464,483\n","20.jpg,800,600,BusRun,241,189,304,215\n","22.jpg,800,600,PlateNo,285,434,433,474\n","22.jpg,800,600,BusRun,470,226,541,246\n","23.jpg,800,600,PlateNo,253,273,448,348\n","23.jpg,800,600,BusRun,171,124,252,151\n","24.jpg,800,600,PlateNo,241,398,385,482\n","24.jpg,800,600,BusRun,504,172,599,205\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iCNYAaC7w6N8","colab_type":"text"},"source":["## Download base model"]},{"cell_type":"code","metadata":{"id":"fbmzgLsOjhMs","colab_type":"code","outputId":"73e0a19f-9a3f-4367-d3b5-02c2506c806f","executionInfo":{"status":"ok","timestamp":1588174796098,"user_tz":-600,"elapsed":1519,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '{model_dir}/models/research'"],"execution_count":68,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"orDCj6ihgUMR","colab_type":"code","outputId":"3fd000ba-3617-4e17-94d6-b86ecb54cff1","executionInfo":{"status":"ok","timestamp":1588174800483,"user_tz":-600,"elapsed":3239,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = model_dir+'/models/research/pretrained_model'\n","\n","# commented if already done\n","#'''\n","print('MODEL_FILE=', MODEL_FILE)\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","print('extracting model file')\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","\n","os.rename(MODEL, DEST_DIR)\n","#'''"],"execution_count":69,"outputs":[{"output_type":"stream","text":["MODEL_FILE= ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz\n","extracting model file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DWby7DIT1AUh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a04a496a-785a-4250-8fa7-4b34eeec06ab","executionInfo":{"status":"ok","timestamp":1588168327910,"user_tz":-600,"elapsed":4702,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}}},"source":["!pwd"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pGhvAObeiIix","colab_type":"code","outputId":"6dd1d32a-994f-4744-ba6d-d46ae00ed4c7","executionInfo":{"status":"ok","timestamp":1588174810109,"user_tz":-600,"elapsed":7787,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["!echo '{DEST_DIR}'\n","!ls -alh '{DEST_DIR}'"],"execution_count":70,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/pretrained_model\n","total 58M\n","-rw------- 1 root root   77 Jan 15 22:35 checkpoint\n","-rw------- 1 root root  13M Jan 15 22:35 frozen_inference_graph.pb\n","-rw------- 1 root root  25M Jan 15 22:35 model.ckpt.data-00000-of-00001\n","-rw------- 1 root root  12K Jan 15 22:35 model.ckpt.index\n","-rw------- 1 root root 7.3M Jan 15 22:36 model.ckpt.meta\n","-rw------- 1 root root  13M Jan 15 22:36 model.tflite\n","-rw------- 1 root root 4.7K Jan 15 22:36 pipeline.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UHnxlfRznPP3","colab_type":"code","outputId":"0a7b06c3-4f6e-43f7-d494-aece29a4cf66","executionInfo":{"status":"ok","timestamp":1588174810110,"user_tz":-600,"elapsed":4882,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"aYW8J5JoLP4I","colab_type":"text"},"source":["# Section 4: Transfer Learning Training"]},{"cell_type":"markdown","metadata":{"id":"MvwtHlLOeRJD","colab_type":"text"},"source":["## Configuring a Training Pipeline"]},{"cell_type":"code","metadata":{"id":"Fa58Txyp6Qut","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"bd05f1c9-58d3-45c6-eadf-a4a5582fcb31","executionInfo":{"status":"ok","timestamp":1588186309824,"user_tz":-600,"elapsed":22901,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}}},"source":["import os\n","pipeline_fname = os.path.join(model_dir+'/models/research/object_detection/samples/configs/', pipeline_file)\n","print(pipeline_fname)\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fG1nCNpUXcRU","colab_type":"code","colab":{}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqbFyhwH6Zzl","colab_type":"code","colab":{}},"source":["# model's .config file is protocol buffer file so can be edited with via google.protobuf\n","import sys\n","import tensorflow as tf\n","from google.protobuf import text_format\n","from object_detection.protos import pipeline_pb2\n","\n","pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n","\n","# read pipeline config file\n","with tf.gfile.GFile(pipeline_fname, \"r\") as f:\n","  proto_str = f.read()\n","  text_format.Merge(proto_str, pipeline_config)\n","\n","# pipeline_config will have all config parameters that can be overwritten\n","pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = train_record_fname\n","pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_fname\n","\n","pipeline_config.train_input_reader.label_map_path = label_map_pbtxt_fname\n","pipeline_config.eval_input_reader[0].label_map_path = label_map_pbtxt_fname\n","\n","if pipeline_config.train_config.fine_tune_checkpoint:\n","  pipeline_config.train_config.fine_tune_checkpoint = fine_tune_checkpoint\n","pipeline_config.train_config.batch_size = batch_size\n","pipeline_config.train_config.num_steps = num_steps\n","\n","# Depending on the base model type, currently there is either ssd or faster_rcnn\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","if pipeline_config.model.ssd:\n","  pipeline_config.model.ssd.num_classes = num_classes\n","elif pipeline_config.model.faster_rcnn:\n","  pipeline_config.model.faster_rcnn.num_classes = num_classes\n","\n","# Save updated config\n","config_text = text_format.MessageToString(pipeline_config)\n","with tf.gfile.Open(pipeline_fname, \"wb\") as f:\n","    f.write(config_text)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IH96bbydOWn","colab_type":"code","outputId":"11055096-9b48-4942-833e-f406e3463df9","executionInfo":{"status":"ok","timestamp":1588174830522,"user_tz":-600,"elapsed":6121,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["!cat '{label_map_pbtxt_fname}'"],"execution_count":75,"outputs":[{"output_type":"stream","text":["item {\n","    id: 1\n","    name: 'BusRun'\n","}\n","\n","item {\n","    id: 2\n","    name: 'PlateNo'\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0F3yKiGVkRLs","colab_type":"code","outputId":"d414894a-526c-4909-f1bf-2369201325cd","executionInfo":{"status":"ok","timestamp":1588174835023,"user_tz":-600,"elapsed":7906,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# look for num_classes: 6, since we have 5 different road signs and 1 person type (total of 6 types) \n","!cat '{pipeline_fname}'"],"execution_count":76,"outputs":[{"output_type":"stream","text":["model {\n","  ssd {\n","    num_classes: 2\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 320\n","        width: 320\n","      }\n","    }\n","    feature_extractor {\n","      type: \"ssd_mobilenet_v3_large\"\n","      depth_multiplier: 1.0\n","      min_depth: 16\n","      conv_hyperparams {\n","        regularizer {\n","          l2_regularizer {\n","            weight: 3.9999999e-05\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            mean: 0.0\n","            stddev: 0.029999999\n","          }\n","        }\n","        activation: RELU_6\n","        batch_norm {\n","          decay: 0.97000003\n","          center: true\n","          scale: true\n","          epsilon: 0.001\n","          train: true\n","        }\n","      }\n","      use_depthwise: true\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    box_predictor {\n","      convolutional_box_predictor {\n","        conv_hyperparams {\n","          regularizer {\n","            l2_regularizer {\n","              weight: 3.9999999e-05\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              mean: 0.0\n","              stddev: 0.029999999\n","            }\n","          }\n","          activation: RELU_6\n","          batch_norm {\n","            decay: 0.97000003\n","            center: true\n","            scale: true\n","            epsilon: 0.001\n","            train: true\n","          }\n","        }\n","        min_depth: 0\n","        max_depth: 0\n","        num_layers_before_predictor: 0\n","        use_dropout: false\n","        dropout_keep_probability: 0.80000001\n","        kernel_size: 3\n","        box_code_size: 4\n","        apply_sigmoid_to_scores: false\n","        class_prediction_bias_init: -4.5999999\n","        use_depthwise: true\n","      }\n","    }\n","    anchor_generator {\n","      ssd_anchor_generator {\n","        num_layers: 6\n","        min_scale: 0.2\n","        max_scale: 0.94999999\n","        aspect_ratios: 1.0\n","        aspect_ratios: 2.0\n","        aspect_ratios: 0.5\n","        aspect_ratios: 3.0\n","        aspect_ratios: 0.33329999\n","      }\n","    }\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 9.9999999e-09\n","        iou_threshold: 0.60000002\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","        use_static_shapes: true\n","      }\n","      score_converter: SIGMOID\n","    }\n","    normalize_loss_by_num_matches: true\n","    loss {\n","      localization_loss {\n","        weighted_smooth_l1 {\n","          delta: 1.0\n","        }\n","      }\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          gamma: 2.0\n","          alpha: 0.75\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    encode_background_as_zeros: true\n","    normalize_loc_loss_by_codesize: true\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","  }\n","}\n","train_config {\n","  batch_size: 12\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    ssd_random_crop {\n","    }\n","  }\n","  sync_replicas: true\n","  optimizer {\n","    momentum_optimizer {\n","      learning_rate {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: 0.40000001\n","          total_steps: 400000\n","          warmup_learning_rate: 0.13333\n","          warmup_steps: 2000\n","        }\n","      }\n","      momentum_optimizer_value: 0.89999998\n","    }\n","    use_moving_average: false\n","  }\n","  num_steps: 5000\n","  startup_delay_steps: 0.0\n","  replicas_to_aggregate: 32\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","train_input_reader {\n","  label_map_path: \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/annotations/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/annotations/train.record\"\n","  }\n","}\n","eval_config {\n","  num_examples: 8000\n","}\n","eval_input_reader {\n","  label_map_path: \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/annotations/label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/annotations/test.record\"\n","  }\n","}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"23TECXvNezIF","colab_type":"text"},"source":["## Run Tensorboard"]},{"cell_type":"code","metadata":{"id":"S7ZACJXsBtSc","colab_type":"code","outputId":"68bd9b3e-3083-4202-b3ca-7f36b480b274","executionInfo":{"status":"ok","timestamp":1588174846907,"user_tz":-600,"elapsed":8971,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":77,"outputs":[{"output_type":"stream","text":["--2020-04-29 15:40:39--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 3.220.228.61, 3.221.30.222, 52.87.72.17, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|3.220.228.61|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.7’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  12.7MB/s    in 1.0s    \n","\n","2020-04-29 15:40:40 (12.7 MB/s) - ‘ngrok-stable-linux-amd64.zip.7’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JOy7E3Hm7Qbf","colab_type":"code","outputId":"6999b369-491f-4e17-8325-dbc409d2f145","executionInfo":{"status":"ok","timestamp":1588168476398,"user_tz":-600,"elapsed":10665,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pwd"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8o6r1o5SC5M","colab_type":"code","colab":{}},"source":["LOG_DIR = model_dir#+'Rerun'\n","get_ipython().system_raw(\n","    'tensorboard --logdir \"{}\" --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxxtJ56mwsPG","colab_type":"code","outputId":"f79eb3fd-5e49-4d91-f90e-2e4767b2f84d","executionInfo":{"status":"ok","timestamp":1588168476399,"user_tz":-600,"elapsed":3196,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["LOG_DIR"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource'"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"Ge1OX7gcSC7S","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5GSGxZNh8rp","colab_type":"text"},"source":["### Get Tensorboard link"]},{"cell_type":"code","metadata":{"id":"rzxm3ljMb85p","colab_type":"code","outputId":"f306aef8-ef94-40eb-9252-788f703b1b9f","executionInfo":{"status":"ok","timestamp":1588174849657,"user_tz":-600,"elapsed":6454,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":80,"outputs":[{"output_type":"stream","text":["http://918d511c.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JDddx2rPfex9","colab_type":"text"},"source":["## Train the model"]},{"cell_type":"markdown","metadata":{"id":"EZc0RFcUjTa-","colab_type":"text"},"source":["Now all inputs are set up, just train the model.   This process may take a few hours.   Since we are saving the model training results (model.ckpt-* files) in our google drive (a persistent storage that will survice the restart of our colab VM instance), we can safely leave and return a few hours later. "]},{"cell_type":"code","metadata":{"id":"QvUx8uoxcR_W","colab_type":"code","colab":{}},"source":["#################### SEND ALERT EMAIL AT FINISH WITH GMAIL OPTIONAL #####################\n","# To send email from Python from your google account, MUST \n","# 1) Enable less secure app\n","# https://myaccount.google.com/lesssecureapps\n","# 2) Disable Unlock Capcha\n","# https://accounts.google.com/b/0/DisplayUnlockCaptcha\n","\n","import smtplib\n","\n","def SendEmail(msg):\n","    with open('/content/gdrive/My Drive/Colab Notebooks/pw.txt') as file:\n","        data = file.readlines()\n","        \n","    gmail_user = 'gehmaid@student.unimelb.edu.au'  \n","    gmail_password = data[0]\n","\n","\n","    sent_from = gmail_user  \n","    to = ['gehmaid@student.unimelb.edu.au']  \n","    subject = msg  \n","    body = '%s\\n\\n- Ghawady' % msg\n","\n","    email_text = \\\n","\"\"\"From: %s\n","To: %s\n","Subject: %s\n","\n","%s\n","\"\"\" % (sent_from, \", \".join(to), subject, body)\n","\n","    server = smtplib.SMTP(\"smtp.gmail.com\", 587)\n","    server.ehlo()\n","    server.starttls()\n","    server.login(gmail_user, gmail_password)\n","    server.sendmail(sent_from, to, email_text)\n","    server.quit()\n","\n","    print(f'Email: \\n{email_text}')\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlOFty-1TYOw","colab_type":"code","outputId":"7ce49eea-126c-4835-bc97-2e8998086e51","executionInfo":{"status":"ok","timestamp":1588186309825,"user_tz":-600,"elapsed":1571,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["num_steps = 5000\n","SendEmail(\"Colab train started\")\n","!python '{model_dir}'/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path='{pipeline_fname}' \\\n","    --model_dir='{trainedmodel_dir}' \\\n","    --alsologtostderr \\\n","    --num_train_steps='{num_steps}' \\\n","    --num_eval_steps='{num_eval_steps}'\n","SendEmail(\"Colab train finished\")"],"execution_count":94,"outputs":[{"output_type":"stream","text":["Email: \n","From: gehmaid@student.unimelb.edu.au\n","To: gehmaid@student.unimelb.edu.au\n","Subject: Colab train started\n","\n","Colab train started\n","\n","- Ghawady\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 16:14:15.219045 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","W0429 16:14:15.223979 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n","\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0429 16:14:15.224123 140127288534912 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0429 16:14:15.224262 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:Maybe overwriting train_steps: 15000\n","I0429 16:14:15.224348 140127288534912 config_util.py:488] Maybe overwriting train_steps: 15000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0429 16:14:15.224430 140127288534912 config_util.py:488] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0429 16:14:15.224499 140127288534912 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0429 16:14:15.224577 140127288534912 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n","INFO:tensorflow:Maybe overwriting load_pretrained: True\n","I0429 16:14:15.224645 140127288534912 config_util.py:488] Maybe overwriting load_pretrained: True\n","INFO:tensorflow:Ignoring config override key: load_pretrained\n","I0429 16:14:15.224711 140127288534912 config_util.py:498] Ignoring config override key: load_pretrained\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0429 16:14:15.225381 140127288534912 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","I0429 16:14:15.225481 140127288534912 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n","INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7185132438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0429 16:14:15.225870 140127288534912 estimator.py:212] Using config: {'_model_dir': '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7185132438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f71851319d8>) includes params argument, but params are not passed to Estimator.\n","W0429 16:14:15.226097 140127288534912 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f71851319d8>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0429 16:14:15.226927 140127288534912 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0429 16:14:15.227128 140127288534912 training.py:612] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0429 16:14:15.227378 140127288534912 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0429 16:14:15.242341 140127288534912 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0429 16:14:15.252555 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0429 16:14:15.252763 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0429 16:14:15.269567 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0429 16:14:15.271196 140127288534912 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0429 16:14:15.276820 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0429 16:14:15.276994 140127288534912 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0429 16:14:15.296548 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n","\n","W0429 16:14:16.434323 140127288534912 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0429 16:14:23.873178 140127288534912 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0429 16:14:23.942532 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0429 16:14:27.109131 140127288534912 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0429 16:14:30.008245 140127288534912 api.py:332] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0429 16:14:33.878255 140127288534912 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","W0429 16:14:33.879766 140127288534912 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0429 16:14:34.542061 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","W0429 16:14:36.110808 140127288534912 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","W0429 16:14:36.550806 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n","INFO:tensorflow:Calling model_fn.\n","I0429 16:14:36.678923 140127288534912 estimator.py:1148] Calling model_fn.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0429 16:14:36.685037 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0429 16:14:36.687609 140127288534912 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0429 16:14:39.033916 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:14:39.043548 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:14:39.123151 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:14:39.201565 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:14:39.293374 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:14:39.376000 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:14:39.466016 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0429 16:14:39.636652 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0429 16:14:42.048993 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0429 16:14:42.056939 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0429 16:14:42.058523 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","W0429 16:14:42.114843 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0429 16:14:42.115234 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0429 16:14:42.120713 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","W0429 16:14:42.136949 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","W0429 16:14:42.137232 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0429 16:14:45.831478 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0429 16:14:46.282311 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","W0429 16:14:46.282571 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0429 16:14:46.282920 140127288534912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","I0429 16:14:46.284130 140127288534912 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","I0429 16:14:48.565219 140127288534912 monitored_session.py:240] Graph was finalized.\n","2020-04-29 16:14:48.565642: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-04-29 16:14:48.572112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-29 16:14:48.572310: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x110f3180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:14:48.572339: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-29 16:14:48.574871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-29 16:14:48.684498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:14:48.685398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x110f2fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:14:48.685436: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-04-29 16:14:48.685653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:14:48.686352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:14:48.686724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:14:48.688872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:14:48.690989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:14:48.691474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:14:48.693653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:14:48.694671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:14:48.698929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:14:48.699067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:14:48.699823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:14:48.700512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:14:48.700582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:14:48.702274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:14:48.702307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:14:48.702323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:14:48.702457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:14:48.703231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:14:48.703915: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-29 16:14:48.703988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-5000\n","I0429 16:14:48.709725 140127288534912 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-5000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","W0429 16:14:51.017307 140127288534912 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file utilities to get mtimes.\n","INFO:tensorflow:Running local_init_op.\n","I0429 16:14:51.747622 140127288534912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0429 16:14:51.961947 140127288534912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 5000 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","I0429 16:14:59.064036 140127288534912 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","2020-04-29 16:15:05.984002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:15:07.423262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","INFO:tensorflow:loss = 10.734819, step = 5000\n","I0429 16:15:09.248872 140127288534912 basic_session_run_hooks.py:262] loss = 10.734819, step = 5000\n","INFO:tensorflow:global_step/sec: 4.13082\n","I0429 16:15:33.456325 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.13082\n","INFO:tensorflow:loss = 10.381696, step = 5100 (24.208 sec)\n","I0429 16:15:33.457288 140127288534912 basic_session_run_hooks.py:260] loss = 10.381696, step = 5100 (24.208 sec)\n","INFO:tensorflow:global_step/sec: 5.13618\n","I0429 16:15:52.926055 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.13618\n","INFO:tensorflow:loss = 10.017759, step = 5200 (19.470 sec)\n","I0429 16:15:52.927055 140127288534912 basic_session_run_hooks.py:260] loss = 10.017759, step = 5200 (19.470 sec)\n","INFO:tensorflow:global_step/sec: 5.11744\n","I0429 16:16:12.467099 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.11744\n","INFO:tensorflow:loss = 9.733587, step = 5300 (19.541 sec)\n","I0429 16:16:12.468190 140127288534912 basic_session_run_hooks.py:260] loss = 9.733587, step = 5300 (19.541 sec)\n","INFO:tensorflow:global_step/sec: 4.98731\n","I0429 16:16:32.517952 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.98731\n","INFO:tensorflow:loss = 9.466801, step = 5400 (20.051 sec)\n","I0429 16:16:32.519284 140127288534912 basic_session_run_hooks.py:260] loss = 9.466801, step = 5400 (20.051 sec)\n","INFO:tensorflow:global_step/sec: 5.09297\n","I0429 16:16:52.152890 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09297\n","INFO:tensorflow:loss = 9.1984625, step = 5500 (19.635 sec)\n","I0429 16:16:52.154637 140127288534912 basic_session_run_hooks.py:260] loss = 9.1984625, step = 5500 (19.635 sec)\n","INFO:tensorflow:global_step/sec: 5.16155\n","I0429 16:17:11.526864 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.16155\n","INFO:tensorflow:loss = 8.756071, step = 5600 (19.373 sec)\n","I0429 16:17:11.528014 140127288534912 basic_session_run_hooks.py:260] loss = 8.756071, step = 5600 (19.373 sec)\n","INFO:tensorflow:global_step/sec: 5.09474\n","I0429 16:17:31.154995 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09474\n","INFO:tensorflow:loss = 8.9592285, step = 5700 (19.628 sec)\n","I0429 16:17:31.155992 140127288534912 basic_session_run_hooks.py:260] loss = 8.9592285, step = 5700 (19.628 sec)\n","INFO:tensorflow:global_step/sec: 5.13075\n","I0429 16:17:50.645349 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.13075\n","INFO:tensorflow:loss = 8.520052, step = 5800 (19.491 sec)\n","I0429 16:17:50.646653 140127288534912 basic_session_run_hooks.py:260] loss = 8.520052, step = 5800 (19.491 sec)\n","INFO:tensorflow:global_step/sec: 5.02365\n","I0429 16:18:10.551164 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.02365\n","INFO:tensorflow:loss = 8.177388, step = 5900 (19.906 sec)\n","I0429 16:18:10.552515 140127288534912 basic_session_run_hooks.py:260] loss = 8.177388, step = 5900 (19.906 sec)\n","INFO:tensorflow:global_step/sec: 5.10865\n","I0429 16:18:30.125772 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.10865\n","INFO:tensorflow:loss = 7.8632197, step = 6000 (19.574 sec)\n","I0429 16:18:30.126864 140127288534912 basic_session_run_hooks.py:260] loss = 7.8632197, step = 6000 (19.574 sec)\n","INFO:tensorflow:global_step/sec: 5.17035\n","I0429 16:18:49.466797 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.17035\n","INFO:tensorflow:loss = 7.6086736, step = 6100 (19.341 sec)\n","I0429 16:18:49.467868 140127288534912 basic_session_run_hooks.py:260] loss = 7.6086736, step = 6100 (19.341 sec)\n","INFO:tensorflow:global_step/sec: 5.11537\n","I0429 16:19:09.015761 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.11537\n","INFO:tensorflow:loss = 7.369473, step = 6200 (19.550 sec)\n","I0429 16:19:09.017392 140127288534912 basic_session_run_hooks.py:260] loss = 7.369473, step = 6200 (19.550 sec)\n","INFO:tensorflow:global_step/sec: 5.06249\n","I0429 16:19:28.768900 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.06249\n","INFO:tensorflow:loss = 7.2013855, step = 6300 (19.753 sec)\n","I0429 16:19:28.770072 140127288534912 basic_session_run_hooks.py:260] loss = 7.2013855, step = 6300 (19.753 sec)\n","INFO:tensorflow:global_step/sec: 5.02385\n","I0429 16:19:48.673997 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.02385\n","INFO:tensorflow:loss = 7.167693, step = 6400 (19.905 sec)\n","I0429 16:19:48.675001 140127288534912 basic_session_run_hooks.py:260] loss = 7.167693, step = 6400 (19.905 sec)\n","INFO:tensorflow:global_step/sec: 5.12814\n","I0429 16:20:08.174190 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.12814\n","INFO:tensorflow:loss = 6.9032083, step = 6500 (19.500 sec)\n","I0429 16:20:08.175316 140127288534912 basic_session_run_hooks.py:260] loss = 6.9032083, step = 6500 (19.500 sec)\n","INFO:tensorflow:global_step/sec: 5.09309\n","I0429 16:20:27.808626 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09309\n","INFO:tensorflow:loss = 6.551442, step = 6600 (19.634 sec)\n","I0429 16:20:27.809725 140127288534912 basic_session_run_hooks.py:260] loss = 6.551442, step = 6600 (19.634 sec)\n","INFO:tensorflow:global_step/sec: 5.08251\n","I0429 16:20:47.483958 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.08251\n","INFO:tensorflow:loss = 6.3783464, step = 6700 (19.676 sec)\n","I0429 16:20:47.485231 140127288534912 basic_session_run_hooks.py:260] loss = 6.3783464, step = 6700 (19.676 sec)\n","INFO:tensorflow:global_step/sec: 5.07038\n","I0429 16:21:07.206353 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.07038\n","INFO:tensorflow:loss = 6.174513, step = 6800 (19.722 sec)\n","I0429 16:21:07.207711 140127288534912 basic_session_run_hooks.py:260] loss = 6.174513, step = 6800 (19.722 sec)\n","INFO:tensorflow:global_step/sec: 4.98243\n","I0429 16:21:27.276861 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.98243\n","INFO:tensorflow:loss = 5.9655633, step = 6900 (20.071 sec)\n","I0429 16:21:27.278497 140127288534912 basic_session_run_hooks.py:260] loss = 5.9655633, step = 6900 (20.071 sec)\n","INFO:tensorflow:global_step/sec: 5.09103\n","I0429 16:21:46.919302 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09103\n","INFO:tensorflow:loss = 5.8389497, step = 7000 (19.642 sec)\n","I0429 16:21:46.920595 140127288534912 basic_session_run_hooks.py:260] loss = 5.8389497, step = 7000 (19.642 sec)\n","INFO:tensorflow:global_step/sec: 5.12029\n","I0429 16:22:06.449385 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.12029\n","INFO:tensorflow:loss = 5.5982723, step = 7100 (19.530 sec)\n","I0429 16:22:06.450612 140127288534912 basic_session_run_hooks.py:260] loss = 5.5982723, step = 7100 (19.530 sec)\n","INFO:tensorflow:global_step/sec: 5.00108\n","I0429 16:22:26.445120 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.00108\n","INFO:tensorflow:loss = 5.5226727, step = 7200 (19.996 sec)\n","I0429 16:22:26.446408 140127288534912 basic_session_run_hooks.py:260] loss = 5.5226727, step = 7200 (19.996 sec)\n","INFO:tensorflow:global_step/sec: 5.04674\n","I0429 16:22:46.259836 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.04674\n","INFO:tensorflow:loss = 5.3612833, step = 7300 (19.815 sec)\n","I0429 16:22:46.260942 140127288534912 basic_session_run_hooks.py:260] loss = 5.3612833, step = 7300 (19.815 sec)\n","INFO:tensorflow:global_step/sec: 5.11332\n","I0429 16:23:05.816620 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.11332\n","INFO:tensorflow:loss = 5.311831, step = 7400 (19.557 sec)\n","I0429 16:23:05.817938 140127288534912 basic_session_run_hooks.py:260] loss = 5.311831, step = 7400 (19.557 sec)\n","INFO:tensorflow:global_step/sec: 5.07824\n","I0429 16:23:25.508456 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.07824\n","INFO:tensorflow:loss = 5.0618267, step = 7500 (19.691 sec)\n","I0429 16:23:25.509389 140127288534912 basic_session_run_hooks.py:260] loss = 5.0618267, step = 7500 (19.691 sec)\n","INFO:tensorflow:global_step/sec: 5.07662\n","I0429 16:23:45.206650 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.07662\n","INFO:tensorflow:loss = 5.091531, step = 7600 (19.699 sec)\n","I0429 16:23:45.208412 140127288534912 basic_session_run_hooks.py:260] loss = 5.091531, step = 7600 (19.699 sec)\n","INFO:tensorflow:global_step/sec: 4.95469\n","I0429 16:24:05.389516 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.95469\n","INFO:tensorflow:loss = 4.719882, step = 7700 (20.182 sec)\n","I0429 16:24:05.390634 140127288534912 basic_session_run_hooks.py:260] loss = 4.719882, step = 7700 (20.182 sec)\n","INFO:tensorflow:global_step/sec: 5.07857\n","I0429 16:24:25.080096 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.07857\n","INFO:tensorflow:loss = 4.460396, step = 7800 (19.691 sec)\n","I0429 16:24:25.081159 140127288534912 basic_session_run_hooks.py:260] loss = 4.460396, step = 7800 (19.691 sec)\n","INFO:tensorflow:global_step/sec: 5.10068\n","I0429 16:24:44.685324 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.10068\n","INFO:tensorflow:loss = 4.3013034, step = 7900 (19.605 sec)\n","I0429 16:24:44.686422 140127288534912 basic_session_run_hooks.py:260] loss = 4.3013034, step = 7900 (19.605 sec)\n","INFO:tensorflow:Saving checkpoints for 7981 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","I0429 16:25:00.586633 140127288534912 basic_session_run_hooks.py:606] Saving checkpoints for 7981 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","I0429 16:25:02.541388 140127288534912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:25:04.970251 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:25:05.077763 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:25:05.197132 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:25:05.304044 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:25:05.410753 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:25:05.518913 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0429 16:25:06.274936 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0429 16:25:06.568609 140127288534912 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/visualization_utils.py:1119: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","W0429 16:25:06.789409 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/utils/visualization_utils.py:1119: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0429 16:25:06.941176 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0429 16:25:07.365771 140127288534912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-04-29T16:25:07Z\n","I0429 16:25:07.381341 140127288534912 evaluation.py:255] Starting evaluation at 2020-04-29T16:25:07Z\n","INFO:tensorflow:Graph was finalized.\n","I0429 16:25:07.943745 140127288534912 monitored_session.py:240] Graph was finalized.\n","2020-04-29 16:25:07.944878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:25:07.945368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:25:07.945485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:25:07.945516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:25:07.945544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:25:07.945567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:25:07.945590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:25:07.945613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:25:07.945635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:25:07.945724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:25:07.946199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:25:07.946565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:25:07.946613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:25:07.946627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:25:07.946636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:25:07.946727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:25:07.947167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:25:07.947545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-7981\n","I0429 16:25:07.950367 140127288534912 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-7981\n","INFO:tensorflow:Running local_init_op.\n","I0429 16:25:09.006958 140127288534912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0429 16:25:09.155507 140127288534912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 23 images.\n","I0429 16:25:12.345603 140125202413312 coco_evaluation.py:205] Performing evaluation on 23 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0429 16:25:12.346148 140125202413312 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0429 16:25:12.348841 140125202413312 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.24s).\n","Accumulating evaluation results...\n","DONE (t=0.03s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.554\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.996\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.525\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.554\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.615\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.628\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.628\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.658\n","INFO:tensorflow:Finished evaluation at 2020-04-29-16:25:13\n","I0429 16:25:13.664414 140127288534912 evaluation.py:275] Finished evaluation at 2020-04-29-16:25:13\n","INFO:tensorflow:Saving dict for global step 7981: DetectionBoxes_Precision/mAP = 0.5544124, DetectionBoxes_Precision/mAP (large) = 0.6205627, DetectionBoxes_Precision/mAP (medium) = 0.5535979, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9955799, DetectionBoxes_Precision/mAP@.75IOU = 0.52499115, DetectionBoxes_Recall/AR@1 = 0.6152174, DetectionBoxes_Recall/AR@10 = 0.62826085, DetectionBoxes_Recall/AR@100 = 0.62826085, DetectionBoxes_Recall/AR@100 (large) = 0.65833336, DetectionBoxes_Recall/AR@100 (medium) = 0.6272727, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.19696099, Loss/localization_loss = 0.1141341, Loss/regularization_loss = 4.048029, Loss/total_loss = 4.359124, global_step = 7981, learning_rate = 0.39977717, loss = 4.359124\n","I0429 16:25:13.664767 140127288534912 estimator.py:2049] Saving dict for global step 7981: DetectionBoxes_Precision/mAP = 0.5544124, DetectionBoxes_Precision/mAP (large) = 0.6205627, DetectionBoxes_Precision/mAP (medium) = 0.5535979, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9955799, DetectionBoxes_Precision/mAP@.75IOU = 0.52499115, DetectionBoxes_Recall/AR@1 = 0.6152174, DetectionBoxes_Recall/AR@10 = 0.62826085, DetectionBoxes_Recall/AR@100 = 0.62826085, DetectionBoxes_Recall/AR@100 (large) = 0.65833336, DetectionBoxes_Recall/AR@100 (medium) = 0.6272727, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.19696099, Loss/localization_loss = 0.1141341, Loss/regularization_loss = 4.048029, Loss/total_loss = 4.359124, global_step = 7981, learning_rate = 0.39977717, loss = 4.359124\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7981: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-7981\n","I0429 16:25:15.111850 140127288534912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 7981: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-7981\n","INFO:tensorflow:global_step/sec: 2.93447\n","I0429 16:25:18.763073 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 2.93447\n","INFO:tensorflow:loss = 4.252202, step = 8000 (34.078 sec)\n","I0429 16:25:18.764245 140127288534912 basic_session_run_hooks.py:260] loss = 4.252202, step = 8000 (34.078 sec)\n","INFO:tensorflow:global_step/sec: 5.05246\n","I0429 16:25:38.555525 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.05246\n","INFO:tensorflow:loss = 4.220579, step = 8100 (19.792 sec)\n","I0429 16:25:38.556696 140127288534912 basic_session_run_hooks.py:260] loss = 4.220579, step = 8100 (19.792 sec)\n","INFO:tensorflow:global_step/sec: 5.04316\n","I0429 16:25:58.384284 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.04316\n","INFO:tensorflow:loss = 3.9786527, step = 8200 (19.829 sec)\n","I0429 16:25:58.385902 140127288534912 basic_session_run_hooks.py:260] loss = 3.9786527, step = 8200 (19.829 sec)\n","INFO:tensorflow:global_step/sec: 5.09801\n","I0429 16:26:17.999751 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09801\n","INFO:tensorflow:loss = 3.879238, step = 8300 (19.615 sec)\n","I0429 16:26:18.000940 140127288534912 basic_session_run_hooks.py:260] loss = 3.879238, step = 8300 (19.615 sec)\n","INFO:tensorflow:global_step/sec: 5.12241\n","I0429 16:26:37.521806 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.12241\n","INFO:tensorflow:loss = 3.7450254, step = 8400 (19.522 sec)\n","I0429 16:26:37.523044 140127288534912 basic_session_run_hooks.py:260] loss = 3.7450254, step = 8400 (19.522 sec)\n","INFO:tensorflow:global_step/sec: 5.13074\n","I0429 16:26:57.012193 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.13074\n","INFO:tensorflow:loss = 3.643086, step = 8500 (19.490 sec)\n","I0429 16:26:57.013293 140127288534912 basic_session_run_hooks.py:260] loss = 3.643086, step = 8500 (19.490 sec)\n","INFO:tensorflow:global_step/sec: 5.08421\n","I0429 16:27:16.680955 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.08421\n","INFO:tensorflow:loss = 3.5513437, step = 8600 (19.669 sec)\n","I0429 16:27:16.682143 140127288534912 basic_session_run_hooks.py:260] loss = 3.5513437, step = 8600 (19.669 sec)\n","INFO:tensorflow:global_step/sec: 5.08709\n","I0429 16:27:36.338516 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.08709\n","INFO:tensorflow:loss = 3.4419613, step = 8700 (19.657 sec)\n","I0429 16:27:36.339597 140127288534912 basic_session_run_hooks.py:260] loss = 3.4419613, step = 8700 (19.657 sec)\n","INFO:tensorflow:global_step/sec: 5.15142\n","I0429 16:27:55.750660 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.15142\n","INFO:tensorflow:loss = 3.3006315, step = 8800 (19.412 sec)\n","I0429 16:27:55.751906 140127288534912 basic_session_run_hooks.py:260] loss = 3.3006315, step = 8800 (19.412 sec)\n","INFO:tensorflow:global_step/sec: 5.14643\n","I0429 16:28:15.181589 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.14643\n","INFO:tensorflow:loss = 3.4011288, step = 8900 (19.431 sec)\n","I0429 16:28:15.183192 140127288534912 basic_session_run_hooks.py:260] loss = 3.4011288, step = 8900 (19.431 sec)\n","INFO:tensorflow:global_step/sec: 4.99193\n","I0429 16:28:35.213935 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.99193\n","INFO:tensorflow:loss = 3.303641, step = 9000 (20.032 sec)\n","I0429 16:28:35.215213 140127288534912 basic_session_run_hooks.py:260] loss = 3.303641, step = 9000 (20.032 sec)\n","INFO:tensorflow:global_step/sec: 5.06671\n","I0429 16:28:54.950595 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.06671\n","INFO:tensorflow:loss = 3.1337929, step = 9100 (19.737 sec)\n","I0429 16:28:54.951915 140127288534912 basic_session_run_hooks.py:260] loss = 3.1337929, step = 9100 (19.737 sec)\n","INFO:tensorflow:global_step/sec: 5.15473\n","I0429 16:29:14.350224 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.15473\n","INFO:tensorflow:loss = 2.9824736, step = 9200 (19.399 sec)\n","I0429 16:29:14.351291 140127288534912 basic_session_run_hooks.py:260] loss = 2.9824736, step = 9200 (19.399 sec)\n","INFO:tensorflow:global_step/sec: 5.17347\n","I0429 16:29:33.679626 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.17347\n","INFO:tensorflow:loss = 2.8587015, step = 9300 (19.330 sec)\n","I0429 16:29:33.680851 140127288534912 basic_session_run_hooks.py:260] loss = 2.8587015, step = 9300 (19.330 sec)\n","INFO:tensorflow:global_step/sec: 5.04314\n","I0429 16:29:53.508535 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.04314\n","INFO:tensorflow:loss = 2.9254096, step = 9400 (19.829 sec)\n","I0429 16:29:53.509628 140127288534912 basic_session_run_hooks.py:260] loss = 2.9254096, step = 9400 (19.829 sec)\n","INFO:tensorflow:global_step/sec: 4.79641\n","I0429 16:30:14.357686 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.79641\n","INFO:tensorflow:loss = 2.817257, step = 9500 (20.849 sec)\n","I0429 16:30:14.358985 140127288534912 basic_session_run_hooks.py:260] loss = 2.817257, step = 9500 (20.849 sec)\n","INFO:tensorflow:global_step/sec: 5.07836\n","I0429 16:30:34.048860 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.07836\n","INFO:tensorflow:loss = 2.5977867, step = 9600 (19.692 sec)\n","I0429 16:30:34.050619 140127288534912 basic_session_run_hooks.py:260] loss = 2.5977867, step = 9600 (19.692 sec)\n","INFO:tensorflow:global_step/sec: 5.15449\n","I0429 16:30:53.449409 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.15449\n","INFO:tensorflow:loss = 2.5930507, step = 9700 (19.400 sec)\n","I0429 16:30:53.450360 140127288534912 basic_session_run_hooks.py:260] loss = 2.5930507, step = 9700 (19.400 sec)\n","INFO:tensorflow:global_step/sec: 5.10258\n","I0429 16:31:13.047358 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.10258\n","INFO:tensorflow:loss = 2.5742927, step = 9800 (19.598 sec)\n","I0429 16:31:13.048708 140127288534912 basic_session_run_hooks.py:260] loss = 2.5742927, step = 9800 (19.598 sec)\n","INFO:tensorflow:global_step/sec: 5.06557\n","I0429 16:31:32.788480 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.06557\n","INFO:tensorflow:loss = 2.4866216, step = 9900 (19.741 sec)\n","I0429 16:31:32.789702 140127288534912 basic_session_run_hooks.py:260] loss = 2.4866216, step = 9900 (19.741 sec)\n","INFO:tensorflow:global_step/sec: 5.09182\n","I0429 16:31:52.427832 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09182\n","INFO:tensorflow:loss = 2.3872168, step = 10000 (19.639 sec)\n","I0429 16:31:52.428958 140127288534912 basic_session_run_hooks.py:260] loss = 2.3872168, step = 10000 (19.639 sec)\n","INFO:tensorflow:global_step/sec: 5.18199\n","I0429 16:32:11.725440 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.18199\n","INFO:tensorflow:loss = 2.3136997, step = 10100 (19.298 sec)\n","I0429 16:32:11.726551 140127288534912 basic_session_run_hooks.py:260] loss = 2.3136997, step = 10100 (19.298 sec)\n","INFO:tensorflow:global_step/sec: 5.13856\n","I0429 16:32:31.186134 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.13856\n","INFO:tensorflow:loss = 2.2283392, step = 10200 (19.461 sec)\n","I0429 16:32:31.187126 140127288534912 basic_session_run_hooks.py:260] loss = 2.2283392, step = 10200 (19.461 sec)\n","INFO:tensorflow:global_step/sec: 5.1254\n","I0429 16:32:50.696778 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.1254\n","INFO:tensorflow:loss = 2.233801, step = 10300 (19.511 sec)\n","I0429 16:32:50.698538 140127288534912 basic_session_run_hooks.py:260] loss = 2.233801, step = 10300 (19.511 sec)\n","INFO:tensorflow:global_step/sec: 5.049\n","I0429 16:33:10.502722 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.049\n","INFO:tensorflow:loss = 2.1893945, step = 10400 (19.806 sec)\n","I0429 16:33:10.504520 140127288534912 basic_session_run_hooks.py:260] loss = 2.1893945, step = 10400 (19.806 sec)\n","INFO:tensorflow:global_step/sec: 5.11387\n","I0429 16:33:30.057406 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.11387\n","INFO:tensorflow:loss = 2.061812, step = 10500 (19.554 sec)\n","I0429 16:33:30.058572 140127288534912 basic_session_run_hooks.py:260] loss = 2.061812, step = 10500 (19.554 sec)\n","INFO:tensorflow:global_step/sec: 5.11818\n","I0429 16:33:49.595587 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.11818\n","INFO:tensorflow:loss = 2.0919504, step = 10600 (19.538 sec)\n","I0429 16:33:49.596912 140127288534912 basic_session_run_hooks.py:260] loss = 2.0919504, step = 10600 (19.538 sec)\n","INFO:tensorflow:global_step/sec: 5.18259\n","I0429 16:34:08.890924 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.18259\n","INFO:tensorflow:loss = 1.9715108, step = 10700 (19.295 sec)\n","I0429 16:34:08.892024 140127288534912 basic_session_run_hooks.py:260] loss = 1.9715108, step = 10700 (19.295 sec)\n","INFO:tensorflow:global_step/sec: 5.10098\n","I0429 16:34:28.495035 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.10098\n","INFO:tensorflow:loss = 1.8714799, step = 10800 (19.604 sec)\n","I0429 16:34:28.496044 140127288534912 basic_session_run_hooks.py:260] loss = 1.8714799, step = 10800 (19.604 sec)\n","INFO:tensorflow:global_step/sec: 5.09503\n","I0429 16:34:48.121982 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.09503\n","INFO:tensorflow:loss = 1.7699943, step = 10900 (19.627 sec)\n","I0429 16:34:48.123221 140127288534912 basic_session_run_hooks.py:260] loss = 1.7699943, step = 10900 (19.627 sec)\n","INFO:tensorflow:Saving checkpoints for 10967 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","I0429 16:35:00.750787 140127288534912 basic_session_run_hooks.py:606] Saving checkpoints for 10967 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","INFO:tensorflow:Calling model_fn.\n","I0429 16:35:02.597863 140127288534912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:35:05.797361 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:35:05.867757 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:35:05.939949 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:35:06.018202 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:35:06.091732 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:35:06.163021 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0429 16:35:07.562487 140127288534912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-04-29T16:35:07Z\n","I0429 16:35:07.578078 140127288534912 evaluation.py:255] Starting evaluation at 2020-04-29T16:35:07Z\n","INFO:tensorflow:Graph was finalized.\n","I0429 16:35:08.057391 140127288534912 monitored_session.py:240] Graph was finalized.\n","2020-04-29 16:35:08.058076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:35:08.058511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:35:08.058630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:35:08.058662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:35:08.058685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:35:08.058706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:35:08.058727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:35:08.058748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:35:08.058769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:35:08.058861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:35:08.059346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:35:08.059712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:35:08.059788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:35:08.059803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:35:08.059812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:35:08.059907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:35:08.060346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:35:08.060722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-10967\n","I0429 16:35:08.063058 140127288534912 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-10967\n","INFO:tensorflow:Running local_init_op.\n","I0429 16:35:09.080861 140127288534912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0429 16:35:09.211860 140127288534912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 23 images.\n","I0429 16:35:12.907680 140123579393792 coco_evaluation.py:205] Performing evaluation on 23 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0429 16:35:12.908233 140123579393792 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0429 16:35:12.909393 140123579393792 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.32s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.702\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.992\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.875\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.678\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.741\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.741\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.716\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.817\n","INFO:tensorflow:Finished evaluation at 2020-04-29-16:35:14\n","I0429 16:35:14.192121 140127288534912 evaluation.py:275] Finished evaluation at 2020-04-29-16:35:14\n","INFO:tensorflow:Saving dict for global step 10967: DetectionBoxes_Precision/mAP = 0.7018739, DetectionBoxes_Precision/mAP (large) = 0.7892375, DetectionBoxes_Precision/mAP (medium) = 0.67756766, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99204385, DetectionBoxes_Precision/mAP@.75IOU = 0.87506515, DetectionBoxes_Recall/AR@1 = 0.74130434, DetectionBoxes_Recall/AR@10 = 0.74130434, DetectionBoxes_Recall/AR@100 = 0.74130434, DetectionBoxes_Recall/AR@100 (large) = 0.81666666, DetectionBoxes_Recall/AR@100 (medium) = 0.71561265, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.1887305, Loss/localization_loss = 0.0534887, Loss/regularization_loss = 1.5986809, Loss/total_loss = 1.8408997, global_step = 10967, learning_rate = 0.39949924, loss = 1.8408997\n","I0429 16:35:14.192471 140127288534912 estimator.py:2049] Saving dict for global step 10967: DetectionBoxes_Precision/mAP = 0.7018739, DetectionBoxes_Precision/mAP (large) = 0.7892375, DetectionBoxes_Precision/mAP (medium) = 0.67756766, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.99204385, DetectionBoxes_Precision/mAP@.75IOU = 0.87506515, DetectionBoxes_Recall/AR@1 = 0.74130434, DetectionBoxes_Recall/AR@10 = 0.74130434, DetectionBoxes_Recall/AR@100 = 0.74130434, DetectionBoxes_Recall/AR@100 (large) = 0.81666666, DetectionBoxes_Recall/AR@100 (medium) = 0.71561265, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.1887305, Loss/localization_loss = 0.0534887, Loss/regularization_loss = 1.5986809, Loss/total_loss = 1.8408997, global_step = 10967, learning_rate = 0.39949924, loss = 1.8408997\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10967: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-10967\n","I0429 16:35:14.200695 140127288534912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 10967: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-10967\n","INFO:tensorflow:global_step/sec: 3.08557\n","I0429 16:35:20.530882 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 3.08557\n","INFO:tensorflow:loss = 1.7845311, step = 11000 (32.409 sec)\n","I0429 16:35:20.532008 140127288534912 basic_session_run_hooks.py:260] loss = 1.7845311, step = 11000 (32.409 sec)\n","INFO:tensorflow:global_step/sec: 5.05532\n","I0429 16:35:40.312079 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.05532\n","INFO:tensorflow:loss = 1.9545445, step = 11100 (19.782 sec)\n","I0429 16:35:40.313527 140127288534912 basic_session_run_hooks.py:260] loss = 1.9545445, step = 11100 (19.782 sec)\n","INFO:tensorflow:global_step/sec: 5.15005\n","I0429 16:35:59.729317 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.15005\n","INFO:tensorflow:loss = 1.8070866, step = 11200 (19.417 sec)\n","I0429 16:35:59.730272 140127288534912 basic_session_run_hooks.py:260] loss = 1.8070866, step = 11200 (19.417 sec)\n","INFO:tensorflow:global_step/sec: 5.15091\n","I0429 16:36:19.143343 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.15091\n","INFO:tensorflow:loss = 1.6461664, step = 11300 (19.414 sec)\n","I0429 16:36:19.144455 140127288534912 basic_session_run_hooks.py:260] loss = 1.6461664, step = 11300 (19.414 sec)\n","INFO:tensorflow:global_step/sec: 5.17973\n","I0429 16:36:38.449360 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.17973\n","INFO:tensorflow:loss = 1.637758, step = 11400 (19.306 sec)\n","I0429 16:36:38.450424 140127288534912 basic_session_run_hooks.py:260] loss = 1.637758, step = 11400 (19.306 sec)\n","INFO:tensorflow:global_step/sec: 5.1622\n","I0429 16:36:57.820990 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.1622\n","INFO:tensorflow:loss = 1.6393433, step = 11500 (19.372 sec)\n","I0429 16:36:57.822234 140127288534912 basic_session_run_hooks.py:260] loss = 1.6393433, step = 11500 (19.372 sec)\n","INFO:tensorflow:global_step/sec: 5.0949\n","I0429 16:37:17.448451 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.0949\n","INFO:tensorflow:loss = 1.6455882, step = 11600 (19.628 sec)\n","I0429 16:37:17.450182 140127288534912 basic_session_run_hooks.py:260] loss = 1.6455882, step = 11600 (19.628 sec)\n","INFO:tensorflow:global_step/sec: 5.0419\n","I0429 16:37:37.282243 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.0419\n","INFO:tensorflow:loss = 1.561596, step = 11700 (19.833 sec)\n","I0429 16:37:37.283357 140127288534912 basic_session_run_hooks.py:260] loss = 1.561596, step = 11700 (19.833 sec)\n","INFO:tensorflow:global_step/sec: 5.08884\n","I0429 16:37:56.933101 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.08884\n","INFO:tensorflow:loss = 1.9648143, step = 11800 (19.651 sec)\n","I0429 16:37:56.934314 140127288534912 basic_session_run_hooks.py:260] loss = 1.9648143, step = 11800 (19.651 sec)\n","INFO:tensorflow:global_step/sec: 5.122\n","I0429 16:38:16.456704 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.122\n","INFO:tensorflow:loss = 1.4200861, step = 11900 (19.524 sec)\n","I0429 16:38:16.457889 140127288534912 basic_session_run_hooks.py:260] loss = 1.4200861, step = 11900 (19.524 sec)\n","INFO:tensorflow:global_step/sec: 4.99878\n","I0429 16:38:36.461575 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.99878\n","INFO:tensorflow:loss = 1.3872404, step = 12000 (20.005 sec)\n","I0429 16:38:36.463002 140127288534912 basic_session_run_hooks.py:260] loss = 1.3872404, step = 12000 (20.005 sec)\n","INFO:tensorflow:global_step/sec: 4.9157\n","I0429 16:38:56.804556 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.9157\n","INFO:tensorflow:loss = 1.4307427, step = 12100 (20.343 sec)\n","I0429 16:38:56.805693 140127288534912 basic_session_run_hooks.py:260] loss = 1.4307427, step = 12100 (20.343 sec)\n","INFO:tensorflow:global_step/sec: 4.87824\n","I0429 16:39:17.303764 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.87824\n","INFO:tensorflow:loss = 1.320007, step = 12200 (20.499 sec)\n","I0429 16:39:17.304987 140127288534912 basic_session_run_hooks.py:260] loss = 1.320007, step = 12200 (20.499 sec)\n","INFO:tensorflow:global_step/sec: 4.88602\n","I0429 16:39:37.770373 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.88602\n","INFO:tensorflow:loss = 1.2440287, step = 12300 (20.467 sec)\n","I0429 16:39:37.772012 140127288534912 basic_session_run_hooks.py:260] loss = 1.2440287, step = 12300 (20.467 sec)\n","INFO:tensorflow:global_step/sec: 4.99474\n","I0429 16:39:57.791391 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.99474\n","INFO:tensorflow:loss = 1.3844736, step = 12400 (20.021 sec)\n","I0429 16:39:57.792564 140127288534912 basic_session_run_hooks.py:260] loss = 1.3844736, step = 12400 (20.021 sec)\n","INFO:tensorflow:global_step/sec: 4.8579\n","I0429 16:40:18.376437 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.8579\n","INFO:tensorflow:loss = 1.2342479, step = 12500 (20.585 sec)\n","I0429 16:40:18.377659 140127288534912 basic_session_run_hooks.py:260] loss = 1.2342479, step = 12500 (20.585 sec)\n","INFO:tensorflow:global_step/sec: 4.91617\n","I0429 16:40:38.717462 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.91617\n","INFO:tensorflow:loss = 1.3368566, step = 12600 (20.341 sec)\n","I0429 16:40:38.718441 140127288534912 basic_session_run_hooks.py:260] loss = 1.3368566, step = 12600 (20.341 sec)\n","INFO:tensorflow:global_step/sec: 4.93458\n","I0429 16:40:58.982633 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.93458\n","INFO:tensorflow:loss = 1.1491135, step = 12700 (20.265 sec)\n","I0429 16:40:58.983599 140127288534912 basic_session_run_hooks.py:260] loss = 1.1491135, step = 12700 (20.265 sec)\n","INFO:tensorflow:global_step/sec: 4.98073\n","I0429 16:41:19.060043 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.98073\n","INFO:tensorflow:loss = 1.1362177, step = 12800 (20.078 sec)\n","I0429 16:41:19.061306 140127288534912 basic_session_run_hooks.py:260] loss = 1.1362177, step = 12800 (20.078 sec)\n","INFO:tensorflow:global_step/sec: 4.83501\n","I0429 16:41:39.742621 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.83501\n","INFO:tensorflow:loss = 1.1186602, step = 12900 (20.683 sec)\n","I0429 16:41:39.744499 140127288534912 basic_session_run_hooks.py:260] loss = 1.1186602, step = 12900 (20.683 sec)\n","INFO:tensorflow:global_step/sec: 4.89425\n","I0429 16:42:00.174624 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.89425\n","INFO:tensorflow:loss = 1.0462756, step = 13000 (20.431 sec)\n","I0429 16:42:00.175739 140127288534912 basic_session_run_hooks.py:260] loss = 1.0462756, step = 13000 (20.431 sec)\n","INFO:tensorflow:global_step/sec: 5.02396\n","I0429 16:42:20.079244 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.02396\n","INFO:tensorflow:loss = 1.0781552, step = 13100 (19.905 sec)\n","I0429 16:42:20.080297 140127288534912 basic_session_run_hooks.py:260] loss = 1.0781552, step = 13100 (19.905 sec)\n","INFO:tensorflow:global_step/sec: 5.05775\n","I0429 16:42:39.850884 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.05775\n","INFO:tensorflow:loss = 1.0111107, step = 13200 (19.772 sec)\n","I0429 16:42:39.852201 140127288534912 basic_session_run_hooks.py:260] loss = 1.0111107, step = 13200 (19.772 sec)\n","INFO:tensorflow:global_step/sec: 5.07911\n","I0429 16:42:59.539368 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 5.07911\n","INFO:tensorflow:loss = 0.94097716, step = 13300 (19.688 sec)\n","I0429 16:42:59.540508 140127288534912 basic_session_run_hooks.py:260] loss = 0.94097716, step = 13300 (19.688 sec)\n","INFO:tensorflow:global_step/sec: 4.90577\n","I0429 16:43:19.923509 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.90577\n","INFO:tensorflow:loss = 0.97831655, step = 13400 (20.384 sec)\n","I0429 16:43:19.924797 140127288534912 basic_session_run_hooks.py:260] loss = 0.97831655, step = 13400 (20.384 sec)\n","INFO:tensorflow:global_step/sec: 4.7853\n","I0429 16:43:40.820814 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.7853\n","INFO:tensorflow:loss = 0.9460572, step = 13500 (20.898 sec)\n","I0429 16:43:40.822619 140127288534912 basic_session_run_hooks.py:260] loss = 0.9460572, step = 13500 (20.898 sec)\n","INFO:tensorflow:global_step/sec: 4.88762\n","I0429 16:44:01.280662 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.88762\n","INFO:tensorflow:loss = 0.94455624, step = 13600 (20.459 sec)\n","I0429 16:44:01.282003 140127288534912 basic_session_run_hooks.py:260] loss = 0.94455624, step = 13600 (20.459 sec)\n","INFO:tensorflow:global_step/sec: 4.65269\n","I0429 16:44:22.773642 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.65269\n","INFO:tensorflow:loss = 0.94272244, step = 13700 (21.493 sec)\n","I0429 16:44:22.774902 140127288534912 basic_session_run_hooks.py:260] loss = 0.94272244, step = 13700 (21.493 sec)\n","INFO:tensorflow:global_step/sec: 4.55491\n","I0429 16:44:44.727994 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.55491\n","INFO:tensorflow:loss = 1.1802287, step = 13800 (21.954 sec)\n","I0429 16:44:44.729383 140127288534912 basic_session_run_hooks.py:260] loss = 1.1802287, step = 13800 (21.954 sec)\n","INFO:tensorflow:Saving checkpoints for 13877 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","I0429 16:45:00.864121 140127288534912 basic_session_run_hooks.py:606] Saving checkpoints for 13877 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0429 16:45:01.035152 140127288534912 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:Calling model_fn.\n","I0429 16:45:03.998987 140127288534912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:45:06.708660 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:45:06.789705 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:45:06.868730 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:45:06.963375 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:45:07.047379 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:45:07.127337 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0429 16:45:08.600690 140127288534912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-04-29T16:45:08Z\n","I0429 16:45:08.617956 140127288534912 evaluation.py:255] Starting evaluation at 2020-04-29T16:45:08Z\n","INFO:tensorflow:Graph was finalized.\n","I0429 16:45:09.348606 140127288534912 monitored_session.py:240] Graph was finalized.\n","2020-04-29 16:45:09.349506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:45:09.350310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:45:09.350479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:45:09.350535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:45:09.350572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:45:09.350607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:45:09.350648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:45:09.350677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:45:09.350706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:45:09.350825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:45:09.351635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:45:09.352305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:45:09.352380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:45:09.352399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:45:09.352413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:45:09.352544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:45:09.353290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:45:09.353917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-13877\n","I0429 16:45:09.359505 140127288534912 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-13877\n","INFO:tensorflow:Running local_init_op.\n","I0429 16:45:11.677596 140127288534912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0429 16:45:11.992269 140127288534912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 23 images.\n","I0429 16:45:15.927007 140123579393792 coco_evaluation.py:205] Performing evaluation on 23 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0429 16:45:15.927605 140123579393792 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0429 16:45:15.929750 140123579393792 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.23s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.594\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.654\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.569\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.749\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.637\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.643\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767\n","INFO:tensorflow:Finished evaluation at 2020-04-29-16:45:16\n","I0429 16:45:16.886212 140127288534912 evaluation.py:275] Finished evaluation at 2020-04-29-16:45:16\n","INFO:tensorflow:Saving dict for global step 13877: DetectionBoxes_Precision/mAP = 0.59359056, DetectionBoxes_Precision/mAP (large) = 0.7490248, DetectionBoxes_Precision/mAP (medium) = 0.56870455, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.65382004, DetectionBoxes_Recall/AR@1 = 0.6369565, DetectionBoxes_Recall/AR@10 = 0.6434783, DetectionBoxes_Recall/AR@100 = 0.6456522, DetectionBoxes_Recall/AR@100 (large) = 0.76666665, DetectionBoxes_Recall/AR@100 (medium) = 0.6187747, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.1332644, Loss/localization_loss = 0.087749526, Loss/regularization_loss = 0.6751287, Loss/total_loss = 0.8961425, global_step = 13877, learning_rate = 0.39912173, loss = 0.8961425\n","I0429 16:45:16.886539 140127288534912 estimator.py:2049] Saving dict for global step 13877: DetectionBoxes_Precision/mAP = 0.59359056, DetectionBoxes_Precision/mAP (large) = 0.7490248, DetectionBoxes_Precision/mAP (medium) = 0.56870455, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.65382004, DetectionBoxes_Recall/AR@1 = 0.6369565, DetectionBoxes_Recall/AR@10 = 0.6434783, DetectionBoxes_Recall/AR@100 = 0.6456522, DetectionBoxes_Recall/AR@100 (large) = 0.76666665, DetectionBoxes_Recall/AR@100 (medium) = 0.6187747, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.1332644, Loss/localization_loss = 0.087749526, Loss/regularization_loss = 0.6751287, Loss/total_loss = 0.8961425, global_step = 13877, learning_rate = 0.39912173, loss = 0.8961425\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13877: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-13877\n","I0429 16:45:16.893173 140127288534912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 13877: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-13877\n","INFO:tensorflow:global_step/sec: 2.64491\n","I0429 16:45:22.536350 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 2.64491\n","INFO:tensorflow:loss = 0.85696894, step = 13900 (37.808 sec)\n","I0429 16:45:22.537491 140127288534912 basic_session_run_hooks.py:260] loss = 0.85696894, step = 13900 (37.808 sec)\n","INFO:tensorflow:global_step/sec: 4.69758\n","I0429 16:45:43.823916 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.69758\n","INFO:tensorflow:loss = 0.8792145, step = 14000 (21.288 sec)\n","I0429 16:45:43.825821 140127288534912 basic_session_run_hooks.py:260] loss = 0.8792145, step = 14000 (21.288 sec)\n","INFO:tensorflow:global_step/sec: 4.66436\n","I0429 16:46:05.263147 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.66436\n","INFO:tensorflow:loss = 0.90359485, step = 14100 (21.439 sec)\n","I0429 16:46:05.264477 140127288534912 basic_session_run_hooks.py:260] loss = 0.90359485, step = 14100 (21.439 sec)\n","INFO:tensorflow:global_step/sec: 4.57353\n","I0429 16:46:27.128056 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.57353\n","INFO:tensorflow:loss = 0.8195451, step = 14200 (21.865 sec)\n","I0429 16:46:27.129191 140127288534912 basic_session_run_hooks.py:260] loss = 0.8195451, step = 14200 (21.865 sec)\n","INFO:tensorflow:global_step/sec: 4.72517\n","I0429 16:46:48.291290 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.72517\n","INFO:tensorflow:loss = 0.79680717, step = 14300 (21.163 sec)\n","I0429 16:46:48.292345 140127288534912 basic_session_run_hooks.py:260] loss = 0.79680717, step = 14300 (21.163 sec)\n","INFO:tensorflow:global_step/sec: 4.76743\n","I0429 16:47:09.266947 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.76743\n","INFO:tensorflow:loss = 0.9563082, step = 14400 (20.976 sec)\n","I0429 16:47:09.268098 140127288534912 basic_session_run_hooks.py:260] loss = 0.9563082, step = 14400 (20.976 sec)\n","INFO:tensorflow:global_step/sec: 4.73096\n","I0429 16:47:30.404341 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.73096\n","INFO:tensorflow:loss = 0.7155236, step = 14500 (21.138 sec)\n","I0429 16:47:30.405770 140127288534912 basic_session_run_hooks.py:260] loss = 0.7155236, step = 14500 (21.138 sec)\n","INFO:tensorflow:global_step/sec: 4.54059\n","I0429 16:47:52.427918 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.54059\n","INFO:tensorflow:loss = 0.7284212, step = 14600 (22.025 sec)\n","I0429 16:47:52.430392 140127288534912 basic_session_run_hooks.py:260] loss = 0.7284212, step = 14600 (22.025 sec)\n","INFO:tensorflow:global_step/sec: 4.6478\n","I0429 16:48:13.943451 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.6478\n","INFO:tensorflow:loss = 0.69408715, step = 14700 (21.514 sec)\n","I0429 16:48:13.944610 140127288534912 basic_session_run_hooks.py:260] loss = 0.69408715, step = 14700 (21.514 sec)\n","INFO:tensorflow:global_step/sec: 4.75614\n","I0429 16:48:34.968933 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.75614\n","INFO:tensorflow:loss = 0.6733724, step = 14800 (21.026 sec)\n","I0429 16:48:34.970234 140127288534912 basic_session_run_hooks.py:260] loss = 0.6733724, step = 14800 (21.026 sec)\n","INFO:tensorflow:global_step/sec: 4.55525\n","I0429 16:48:56.921616 140127288534912 basic_session_run_hooks.py:692] global_step/sec: 4.55525\n","INFO:tensorflow:loss = 0.7401498, step = 14900 (21.953 sec)\n","I0429 16:48:56.922884 140127288534912 basic_session_run_hooks.py:260] loss = 0.7401498, step = 14900 (21.953 sec)\n","INFO:tensorflow:Saving checkpoints for 15000 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","I0429 16:49:18.456797 140127288534912 basic_session_run_hooks.py:606] Saving checkpoints for 15000 into /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0429 16:49:19.690880 140127288534912 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:Calling model_fn.\n","I0429 16:49:20.396993 140127288534912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:23.456956 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:23.585177 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:23.711884 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:23.872351 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:23.997830 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:24.136358 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:Done calling model_fn.\n","I0429 16:49:26.067152 140127288534912 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-04-29T16:49:26Z\n","I0429 16:49:26.084303 140127288534912 evaluation.py:255] Starting evaluation at 2020-04-29T16:49:26Z\n","INFO:tensorflow:Graph was finalized.\n","I0429 16:49:26.597539 140127288534912 monitored_session.py:240] Graph was finalized.\n","2020-04-29 16:49:26.598454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:26.599002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:49:26.599125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:49:26.599158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:49:26.599185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:49:26.599211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:49:26.599242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:49:26.599267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:49:26.599290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:49:26.599380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:26.599848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:26.600267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:49:26.600315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:49:26.600330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:49:26.600341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:49:26.600441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:26.600896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:26.601333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:49:26.604248 140127288534912 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","INFO:tensorflow:Running local_init_op.\n","I0429 16:49:27.981333 140127288534912 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0429 16:49:28.179764 140127288534912 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 23 images.\n","I0429 16:49:33.288237 140123579393792 coco_evaluation.py:205] Performing evaluation on 23 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0429 16:49:33.288668 140123579393792 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0429 16:49:33.289805 140123579393792 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.33s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.640\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.620\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.643\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n","INFO:tensorflow:Finished evaluation at 2020-04-29-16:49:34\n","I0429 16:49:34.764593 140127288534912 evaluation.py:275] Finished evaluation at 2020-04-29-16:49:34\n","INFO:tensorflow:Saving dict for global step 15000: DetectionBoxes_Precision/mAP = 0.5953013, DetectionBoxes_Precision/mAP (large) = 0.73160064, DetectionBoxes_Precision/mAP (medium) = 0.5560557, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.6402095, DetectionBoxes_Recall/AR@1 = 0.6195652, DetectionBoxes_Recall/AR@10 = 0.6434783, DetectionBoxes_Recall/AR@100 = 0.6434783, DetectionBoxes_Recall/AR@100 (large) = 0.75, DetectionBoxes_Recall/AR@100 (medium) = 0.62806326, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.1290514, Loss/localization_loss = 0.10700949, Loss/regularization_loss = 0.4938291, Loss/total_loss = 0.72989005, global_step = 15000, learning_rate = 0.39894795, loss = 0.72989005\n","I0429 16:49:34.764983 140127288534912 estimator.py:2049] Saving dict for global step 15000: DetectionBoxes_Precision/mAP = 0.5953013, DetectionBoxes_Precision/mAP (large) = 0.73160064, DetectionBoxes_Precision/mAP (medium) = 0.5560557, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 1.0, DetectionBoxes_Precision/mAP@.75IOU = 0.6402095, DetectionBoxes_Recall/AR@1 = 0.6195652, DetectionBoxes_Recall/AR@10 = 0.6434783, DetectionBoxes_Recall/AR@100 = 0.6434783, DetectionBoxes_Recall/AR@100 (large) = 0.75, DetectionBoxes_Recall/AR@100 (medium) = 0.62806326, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 0.1290514, Loss/localization_loss = 0.10700949, Loss/regularization_loss = 0.4938291, Loss/total_loss = 0.72989005, global_step = 15000, learning_rate = 0.39894795, loss = 0.72989005\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:49:34.771875 140127288534912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 15000: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0429 16:49:34.773479 140127288534912 exporter.py:410] Performing the final export in the end of training.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0429 16:49:34.786613 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","INFO:tensorflow:Calling model_fn.\n","I0429 16:49:35.150094 140127288534912 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:37.548440 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:37.627581 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:37.708772 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:37.788904 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:37.881082 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:49:37.962811 140127288534912 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0429 16:49:38.271597 140127288534912 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0429 16:49:38.584673 140127288534912 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0429 16:49:38.585011 140127288534912 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0429 16:49:38.585716 140127288534912 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0429 16:49:38.585844 140127288534912 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0429 16:49:38.585932 140127288534912 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0429 16:49:38.586025 140127288534912 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0429 16:49:38.586097 140127288534912 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2020-04-29 16:49:38.586754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:38.587260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:49:38.587359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:49:38.587386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:49:38.587414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:49:38.587437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:49:38.587461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:49:38.587486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:49:38.587513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:49:38.587598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:38.588115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:38.588527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:49:38.588570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:49:38.588584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:49:38.588594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:49:38.588704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:38.589184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:49:38.589618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:49:38.594019 140127288534912 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","INFO:tensorflow:Assets added to graph.\n","I0429 16:49:39.298295 140127288534912 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0429 16:49:39.298570 140127288534912 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/export/Servo/temp-b'1588178974'/saved_model.pb\n","I0429 16:49:41.117536 140127288534912 builder_impl.py:425] SavedModel written to: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/export/Servo/temp-b'1588178974'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 0.7568763.\n","I0429 16:49:41.620636 140127288534912 estimator.py:371] Loss for final step: 0.7568763.\n","Email: \n","From: gehmaid@student.unimelb.edu.au\n","To: gehmaid@student.unimelb.edu.au\n","Subject: Colab train finished\n","\n","Colab train finished\n","\n","- Ghawady\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gp1KqA2JcZN7","colab_type":"code","outputId":"65456bcd-96b8-4960-fa8b-383695fb0699","executionInfo":{"status":"ok","timestamp":1588169426877,"user_tz":-600,"elapsed":909401,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["!ls -ltra '{trainedmodel_dir}'"],"execution_count":30,"outputs":[{"output_type":"stream","text":["total 65921\n","-rw------- 1 root root 10669511 Apr 29 13:57 graph.pbtxt\n","-rw------- 1 root root    25149 Apr 29 13:57 model.ckpt-0.index\n","-rw------- 1 root root  7653760 Apr 29 13:57 model.ckpt-0.data-00000-of-00001\n","-rw------- 1 root root  5091964 Apr 29 13:57 model.ckpt-0.meta\n","-rw------- 1 root root    25149 Apr 29 14:07 model.ckpt-4122.index\n","-rw------- 1 root root  7653760 Apr 29 14:07 model.ckpt-4122.data-00000-of-00001\n","-rw------- 1 root root  5091964 Apr 29 14:07 model.ckpt-4122.meta\n","drwx------ 2 root root     4096 Apr 29 14:07 eval_0\n","-rw------- 1 root root  5091964 Apr 29 14:10 model.ckpt-5000.meta\n","-rw------- 1 root root    25149 Apr 29 14:10 model.ckpt-5000.index\n","-rw------- 1 root root  7653760 Apr 29 14:10 model.ckpt-5000.data-00000-of-00001\n","-rw------- 1 root root      176 Apr 29 14:10 checkpoint\n","drwx------ 3 root root     4096 Apr 29 14:10 export\n","-rw------- 1 root root 18508676 Apr 29 14:10 events.out.tfevents.1588168643.b4c3954872cb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y4Kzh3_JLVW-","colab_type":"text"},"source":["# Section 5: Save and Convert Model Output"]},{"cell_type":"markdown","metadata":{"id":"OmSESMetj1sa","colab_type":"text"},"source":["## Exporting a Trained Inference Graph\n","Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"]},{"cell_type":"code","metadata":{"id":"r5eIS-RNVIRx","colab_type":"code","colab":{}},"source":["import os\n","import re\n","import numpy as np\n","\n","output_directory = trainedmodel_dir + '/fine_tuned_model'\n","os.makedirs(output_directory, exist_ok=True)\n","!ls '{output_directory}'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6R0Yz7tIVO9C","colab_type":"code","outputId":"205562e0-d25e-407e-ad3d-b332f3c21610","executionInfo":{"status":"ok","timestamp":1588186309826,"user_tz":-600,"elapsed":1389,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["lst = os.listdir(trainedmodel_dir)\n","# find the last model checkpoint file, i.e. model.ckpt-1000.meta\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(trainedmodel_dir, last_model)\n","print(last_model_path)"],"execution_count":96,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"90CjhkueVRpi","colab_type":"code","outputId":"4a0d61ed-6afa-4af7-c6ed-383a2c5ac66f","executionInfo":{"status":"ok","timestamp":1588186309827,"user_tz":-600,"elapsed":1328,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!echo creates the frozen inference graph in fine_tune_model\n","# there is an \"Incomplete shape\" message.  but we can safely ignore that. \n","\n","!python '{model_dir}'/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path='{pipeline_fname}' \\\n","    --output_directory='{output_directory}' \\\n","    --trained_checkpoint_prefix='{last_model_path}'"],"execution_count":97,"outputs":[{"output_type":"stream","text":["creates the frozen inference graph in fine_tune_model\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 16:50:30.429763 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0429 16:50:30.438804 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0429 16:50:30.439638 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0429 16:50:30.473362 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0429 16:50:30.501935 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0429 16:50:30.506367 140591431976832 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0429 16:50:33.454652 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0429 16:50:33.471779 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:50:33.472120 140591431976832 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:50:33.616783 140591431976832 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:50:33.781199 140591431976832 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:50:33.922358 140591431976832 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:50:34.058835 140591431976832 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:50:34.200598 140591431976832 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/post_processing.py:1106: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0429 16:50:34.616217 140591431976832 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/post_processing.py:1106: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0429 16:50:34.939547 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0429 16:50:34.939952 140591431976832 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0429 16:50:34.945160 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0429 16:50:34.945457 140591431976832 deprecation.py:323] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0429 16:50:34.947249 140591431976832 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","215 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/2.17m params)\n","  BoxPredictor_0 (--/26.23k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/8.08k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x672x12, 8.06k/8.06k params)\n","    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/6.05k params)\n","      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x672x1, 6.05k/6.05k params)\n","    BoxPredictor_0/ClassPredictor (--/6.06k params)\n","      BoxPredictor_0/ClassPredictor/biases (9, 9/9 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x672x9, 6.05k/6.05k params)\n","    BoxPredictor_0/ClassPredictor_depthwise (--/6.05k params)\n","      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x672x1, 6.05k/6.05k params)\n","  BoxPredictor_1 (--/28.84k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/11.54k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x480x24, 11.52k/11.52k params)\n","    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/4.32k params)\n","      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x480x1, 4.32k/4.32k params)\n","    BoxPredictor_1/ClassPredictor (--/8.66k params)\n","      BoxPredictor_1/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x480x18, 8.64k/8.64k params)\n","    BoxPredictor_1/ClassPredictor_depthwise (--/4.32k params)\n","      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x480x1, 4.32k/4.32k params)\n","  BoxPredictor_2 (--/30.76k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n","      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","    BoxPredictor_2/ClassPredictor (--/9.23k params)\n","      BoxPredictor_2/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n","    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n","      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","  BoxPredictor_3 (--/15.40k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","    BoxPredictor_3/ClassPredictor (--/4.63k params)\n","      BoxPredictor_3/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","  BoxPredictor_4 (--/15.40k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","    BoxPredictor_4/ClassPredictor (--/4.63k params)\n","      BoxPredictor_4/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n","    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","  BoxPredictor_5 (--/7.72k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n","      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","    BoxPredictor_5/ClassPredictor (--/2.32k params)\n","      BoxPredictor_5/ClassPredictor/biases (18, 18/18 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x18, 2.30k/2.30k params)\n","    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n","      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","  FeatureExtractor (--/2.05m params)\n","    FeatureExtractor/MobilenetV3 (--/2.05m params)\n","      FeatureExtractor/MobilenetV3/Conv (--/432 params)\n","        FeatureExtractor/MobilenetV3/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/Conv/weights (3x3x3x16, 432/432 params)\n","      FeatureExtractor/MobilenetV3/Conv_1 (--/38.40k params)\n","        FeatureExtractor/MobilenetV3/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/Conv_1/weights (1x1x80x480, 38.40k/38.40k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv (--/400 params)\n","        FeatureExtractor/MobilenetV3/expanded_conv/depthwise (--/144 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv/depthwise/depthwise_weights (3x3x16x1, 144/144 params)\n","        FeatureExtractor/MobilenetV3/expanded_conv/project (--/256 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv/project/weights (1x1x16x16, 256/256 params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_1 (--/3.14k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise (--/576 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_1/depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_1/expand (--/1.02k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_1/expand/weights (1x1x16x64, 1.02k/1.02k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_1/project (--/1.54k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_1/project/weights (1x1x64x24, 1.54k/1.54k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_10 (--/212.28k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise (--/4.32k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/depthwise/depthwise_weights (3x3x480x1, 4.32k/4.32k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_10/expand (--/38.40k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/expand/weights (1x1x80x480, 38.40k/38.40k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_10/project (--/53.76k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/project/weights (1x1x480x112, 53.76k/53.76k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite (--/115.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv (--/57.72k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/biases (120, 120/120 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv/weights (1x1x480x120, 57.60k/57.60k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1 (--/58.08k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/biases (480, 480/480 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_10/squeeze_excite/Conv_1/weights (1x1x120x480, 57.60k/57.60k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_11 (--/383.21k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_11/depthwise (--/6.05k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/depthwise/depthwise_weights (3x3x672x1, 6.05k/6.05k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_11/expand (--/75.26k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/expand/weights (1x1x112x672, 75.26k/75.26k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_11/project (--/75.26k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/project/weights (1x1x672x112, 75.26k/75.26k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite (--/226.63k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv (--/113.06k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv/biases (168, 168/168 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv/weights (1x1x672x168, 112.90k/112.90k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv_1 (--/113.57k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv_1/biases (672, 672/672 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_11/squeeze_excite/Conv_1/weights (1x1x168x672, 112.90k/112.90k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_12 (--/372.46k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_12/depthwise (--/16.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/depthwise/depthwise_weights (5x5x672x1, 16.80k/16.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_12/expand (--/75.26k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/expand/weights (1x1x112x672, 75.26k/75.26k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_12/project (--/53.76k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/project/weights (1x1x672x80, 53.76k/53.76k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite (--/226.63k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv (--/113.06k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv/biases (168, 168/168 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv/weights (1x1x672x168, 112.90k/112.90k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv_1 (--/113.57k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv_1/biases (672, 672/672 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_12/squeeze_excite/Conv_1/weights (1x1x168x672, 112.90k/112.90k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_13 (--/204.60k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_13/depthwise (--/12.00k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/depthwise/depthwise_weights (5x5x480x1, 12.00k/12.00k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_13/expand (--/38.40k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/expand/weights (1x1x80x480, 38.40k/38.40k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_13/project (--/38.40k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/project/weights (1x1x480x80, 38.40k/38.40k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite (--/115.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv (--/57.72k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv/biases (120, 120/120 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv/weights (1x1x480x120, 57.60k/57.60k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv_1 (--/58.08k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv_1/biases (480, 480/480 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_13/squeeze_excite/Conv_1/weights (1x1x120x480, 57.60k/57.60k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_14 (--/204.60k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_14/depthwise (--/12.00k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/depthwise/depthwise_weights (5x5x480x1, 12.00k/12.00k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_14/expand (--/38.40k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/expand/weights (1x1x80x480, 38.40k/38.40k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_14/project (--/38.40k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/project/weights (1x1x480x80, 38.40k/38.40k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite (--/115.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv (--/57.72k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv/biases (120, 120/120 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv/weights (1x1x480x120, 57.60k/57.60k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv_1 (--/58.08k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv_1/biases (480, 480/480 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_14/squeeze_excite/Conv_1/weights (1x1x120x480, 57.60k/57.60k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_2 (--/4.10k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise (--/648 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_2/depthwise/depthwise_weights (3x3x72x1, 648/648 params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_2/expand (--/1.73k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_2/expand/weights (1x1x24x72, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_2/project (--/1.73k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_2/project/weights (1x1x72x24, 1.73k/1.73k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_3 (--/9.96k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise (--/1.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/depthwise/depthwise_weights (5x5x72x1, 1.80k/1.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_3/expand (--/1.73k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/expand/weights (1x1x24x72, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_3/project (--/2.88k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/project/weights (1x1x72x40, 2.88k/2.88k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite (--/3.55k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv (--/1.75k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/biases (24, 24/24 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv/weights (1x1x72x24, 1.73k/1.73k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1 (--/1.80k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/biases (72, 72/72 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_3/squeeze_excite/Conv_1/weights (1x1x24x72, 1.73k/1.73k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_4 (--/20.43k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise (--/3.00k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_4/expand (--/4.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/expand/weights (1x1x40x120, 4.80k/4.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_4/project (--/4.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/project/weights (1x1x120x40, 4.80k/4.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite (--/7.83k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv (--/3.87k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/biases (32, 32/32 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1 (--/3.96k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/biases (120, 120/120 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_4/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_5 (--/20.43k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise (--/3.00k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/depthwise/depthwise_weights (5x5x120x1, 3.00k/3.00k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_5/expand (--/4.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/expand/weights (1x1x40x120, 4.80k/4.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_5/project (--/4.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/project/weights (1x1x120x40, 4.80k/4.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite (--/7.83k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv (--/3.87k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/biases (32, 32/32 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv/weights (1x1x120x32, 3.84k/3.84k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1 (--/3.96k params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/biases (120, 120/120 params)\n","            FeatureExtractor/MobilenetV3/expanded_conv_5/squeeze_excite/Conv_1/weights (1x1x32x120, 3.84k/3.84k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_6 (--/30.96k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise (--/2.16k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_6/depthwise/depthwise_weights (3x3x240x1, 2.16k/2.16k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_6/expand (--/9.60k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_6/expand/weights (1x1x40x240, 9.60k/9.60k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_6/project (--/19.20k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_6/project/weights (1x1x240x80, 19.20k/19.20k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_7 (--/33.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise (--/1.80k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_7/depthwise/depthwise_weights (3x3x200x1, 1.80k/1.80k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_7/expand (--/16.00k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_7/expand/weights (1x1x80x200, 16.00k/16.00k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_7/project (--/16.00k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_7/project/weights (1x1x200x80, 16.00k/16.00k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_8 (--/31.10k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise (--/1.66k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_8/depthwise/depthwise_weights (3x3x184x1, 1.66k/1.66k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_8/expand (--/14.72k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_8/expand/weights (1x1x80x184, 14.72k/14.72k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_8/project (--/14.72k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_8/project/weights (1x1x184x80, 14.72k/14.72k params)\n","      FeatureExtractor/MobilenetV3/expanded_conv_9 (--/31.10k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise (--/1.66k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_9/depthwise/depthwise_weights (3x3x184x1, 1.66k/1.66k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_9/expand (--/14.72k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_9/expand/weights (1x1x80x184, 14.72k/14.72k params)\n","        FeatureExtractor/MobilenetV3/expanded_conv_9/project (--/14.72k params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV3/expanded_conv_9/project/weights (1x1x184x80, 14.72k/14.72k params)\n","      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_2_1x1_256 (--/122.88k params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_2_1x1_256/weights (1x1x480x256, 122.88k/122.88k params)\n","      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n","      FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV3/layer_17_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n","\n","======================End of Report==========================\n","215 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/19.29k flops)\n","  MultipleGridAnchorGenerator/sub (2.40k/2.40k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.40k/2.40k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.40k/2.40k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_2 (800/800 flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_1 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/mul (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/GreaterEqual (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_3 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_2 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_3 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul_2 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum_1 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/Scale/mul (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Minimum (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_3 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_2 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum_1 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow/Maximum (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_2 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub_1 (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Area/sub (200/200 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Sum (199/199 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less_1 (100/100 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Less (100/100 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul_1 (100/100 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/mul (100/100 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_17 (20/20 flops)\n","  MultipleGridAnchorGenerator/mul_18 (20/20 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0429 16:50:36.444843 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0429 16:50:37.448832 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-04-29 16:50:37.450522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-29 16:50:37.453588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.454184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:50:37.454508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:50:37.456247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:50:37.458102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:50:37.458490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:50:37.460444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:50:37.461742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:50:37.465599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:50:37.465752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.466436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.466959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:50:37.467403: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-04-29 16:50:37.472738: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-29 16:50:37.473013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2085100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:50:37.473044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-29 16:50:37.567050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.567783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20852c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:50:37.567817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-04-29 16:50:37.568057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.568620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:50:37.568700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:50:37.568728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:50:37.568758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:50:37.568783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:50:37.568806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:50:37.568829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:50:37.568852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:50:37.568929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.569520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.570049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:50:37.570127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:50:37.571449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:50:37.571478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:50:37.571490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:50:37.571615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.572184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:37.572721: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-29 16:50:37.572775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:50:37.576366 140591431976832 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0429 16:50:39.057507 140591431976832 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-04-29 16:50:39.827784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:39.828612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:50:39.828744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:50:39.828781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:50:39.828808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:50:39.828840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:50:39.828873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:50:39.828897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:50:39.828922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:50:39.829055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:39.829883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:39.830579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:50:39.830633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:50:39.830651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:50:39.830665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:50:39.830792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:39.831581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:39.832379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:50:39.835896 140591431976832 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0429 16:50:40.863287 140591431976832 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0429 16:50:40.863583 140591431976832 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 406 variables.\n","I0429 16:50:41.697947 140591431976832 graph_util_impl.py:334] Froze 406 variables.\n","INFO:tensorflow:Converted 406 variables to const ops.\n","I0429 16:50:41.894408 140591431976832 graph_util_impl.py:394] Converted 406 variables to const ops.\n","2020-04-29 16:50:42.170025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:42.170879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:50:42.171076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:50:42.171123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:50:42.171158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:50:42.171187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:50:42.171216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:50:42.171247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:50:42.171279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:50:42.171403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:42.172321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:42.173095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:50:42.173154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:50:42.173176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:50:42.173190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:50:42.173326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:42.174229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:50:42.175059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0429 16:50:42.990186 140591431976832 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","Traceback (most recent call last):\n","  File \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_inference_graph.py\", line 162, in <module>\n","    tf.app.run()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_inference_graph.py\", line 158, in main\n","    write_inference_graph=FLAGS.write_inference_graph)\n","  File \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py\", line 510, in export_inference_graph\n","    write_inference_graph=write_inference_graph)\n","  File \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py\", line 466, in _export_inference_graph\n","    placeholder_tensor, outputs)\n","  File \"/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/exporter.py\", line 306, in write_saved_model\n","    builder = tf.saved_model.builder.SavedModelBuilder(saved_model_path)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/builder_impl.py\", line 436, in __init__\n","    super(SavedModelBuilder, self).__init__(export_dir=export_dir)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/builder_impl.py\", line 103, in __init__\n","    \"specified directory: %s\" % export_dir)\n","AssertionError: Export directory already exists, and isn't empty. Please choose a different export directory, or delete all the contents of the specified directory: /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/fine_tuned_model/saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SHcirc8qVa04","colab_type":"code","outputId":"82183cc5-6e11-4c2b-ae15-4f77da8c3cc4","executionInfo":{"status":"ok","timestamp":1588186309827,"user_tz":-600,"elapsed":1277,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\n","# create the tensorflow lite graph\n","!python '{model_dir}'/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path='{pipeline_fname}' \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true"],"execution_count":98,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 16:50:58.856555 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0429 16:50:58.868901 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0429 16:50:58.870098 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0429 16:50:58.877710 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0429 16:50:58.882364 140223803246464 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0429 16:51:02.034647 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0429 16:51:02.046065 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:02.046305 140223803246464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:02.252292 140223803246464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:02.333254 140223803246464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:02.426475 140223803246464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:02.509949 140223803246464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:02.588803 140223803246464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0429 16:51:02.681072 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-04-29 16:51:02.682380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-29 16:51:02.685207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.685743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:02.686028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:02.687699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:02.689473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:02.689789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:02.691438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:02.692615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:02.696236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:02.696402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.697043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.697550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:02.697909: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-04-29 16:51:02.703098: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-29 16:51:02.703293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f5cf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:51:02.703321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-29 16:51:02.791823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.792680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f5cd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:51:02.792728: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-04-29 16:51:02.792927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.793478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:02.793555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:02.793580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:02.793602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:02.793627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:02.793653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:02.793673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:02.793694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:02.793767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.794355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.794814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:02.794894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:02.796123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:51:02.796149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:51:02.796161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:51:02.796270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.796816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:02.797343: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-29 16:51:02.797386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0429 16:51:02.939726 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0429 16:51:02.943198 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0429 16:51:03.253779 140223803246464 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0429 16:51:03.288127 140223803246464 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-04-29 16:51:03.769932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:03.770513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:03.770601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:03.770628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:03.770672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:03.770698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:03.770723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:03.770745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:03.770768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:03.770858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:03.771534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:03.772290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:03.772348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:51:03.772373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:51:03.772384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:51:03.772497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:03.773084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:03.773617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:51:03.776128 140223803246464 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0429 16:51:05.094611 140223803246464 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0429 16:51:05.094895 140223803246464 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 406 variables.\n","I0429 16:51:05.483345 140223803246464 graph_util_impl.py:334] Froze 406 variables.\n","INFO:tensorflow:Converted 406 variables to const ops.\n","I0429 16:51:05.544624 140223803246464 graph_util_impl.py:394] Converted 406 variables to const ops.\n","2020-04-29 16:51:05.637747: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cko618o2VeAA","colab_type":"code","outputId":"236e9583-1541-4b75-dda7-b8c7c5146107","executionInfo":{"status":"ok","timestamp":1588186309827,"user_tz":-600,"elapsed":1209,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193\n","# create the tensorflow lite graph\n","!python '{model_dir}'/models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path='{pipeline_fname}' \\\n","    --trained_checkpoint_prefix='{last_model_path}' \\\n","    --output_directory='{output_directory}' \\\n","    --add_postprocessing_op=true"],"execution_count":99,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0429 16:51:21.370703 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0429 16:51:21.376410 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0429 16:51:21.377127 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0429 16:51:21.381324 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0429 16:51:21.384595 139947338475392 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0429 16:51:23.866622 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0429 16:51:23.883679 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:23.883908 139947338475392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:24.195863 139947338475392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:24.327183 139947338475392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:24.455366 139947338475392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:24.609806 139947338475392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0429 16:51:24.752244 139947338475392 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0429 16:51:24.899717 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-04-29 16:51:24.901392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-29 16:51:24.906169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:24.906930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:24.907542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:24.910934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:24.914716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:24.915505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:24.919166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:24.921879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:24.929980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:24.930260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:24.931223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:24.931957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:24.932677: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-04-29 16:51:24.946754: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-29 16:51:24.947879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f60f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:51:24.947925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-29 16:51:25.088546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:25.089899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f60d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:51:25.089942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-04-29 16:51:25.090206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:25.090947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:25.091069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:25.091107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:25.091291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:25.091333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:25.091375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:25.091405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:25.091432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:25.091524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:25.092395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:25.093144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:25.093242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:25.094773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:51:25.094806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:51:25.094821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:51:25.094995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:25.095801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:25.096579: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-29 16:51:25.096640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0429 16:51:25.366913 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0429 16:51:25.372146 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0429 16:51:25.852696 139947338475392 module_wrapper.py:139] From /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0429 16:51:25.917052 139947338475392 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-04-29 16:51:26.745142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:26.745748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:26.745839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:26.745872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:26.745899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:26.745929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:26.745953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:26.745994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:26.746018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:26.746106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:26.746670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:26.747170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:26.747214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:51:26.747229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:51:26.747238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:51:26.747340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:26.747852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:26.748525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","I0429 16:51:26.752210 139947338475392 saver.py:1284] Restoring parameters from /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/model.ckpt-15000\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0429 16:51:27.524391 139947338475392 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0429 16:51:27.524662 139947338475392 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 406 variables.\n","I0429 16:51:27.924798 139947338475392 graph_util_impl.py:334] Froze 406 variables.\n","INFO:tensorflow:Converted 406 variables to const ops.\n","I0429 16:51:27.974999 139947338475392 graph_util_impl.py:394] Converted 406 variables to const ops.\n","2020-04-29 16:51:28.077619: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BAkuZNHtVimx","colab_type":"code","outputId":"f415bca1-fd53-4e81-fe06-30fd0c5a0d04","executionInfo":{"status":"ok","timestamp":1588186309828,"user_tz":-600,"elapsed":1148,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/detect.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops\n","  #--output_arrays represent four arrays: detection_boxes, detection_classes, detection_scores, and num_detections."],"execution_count":100,"outputs":[{"output_type":"stream","text":["CONVERTING frozen graph to quantized TF Lite file...\n","2020-04-29 16:51:56.573383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-04-29 16:51:56.576123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.576663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:56.576914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:56.578614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:56.580526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:56.580896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:56.582648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:56.583728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:56.587631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:56.587754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.588343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.588816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:56.589224: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-04-29 16:51:56.594626: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2020-04-29 16:51:56.594842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bbca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:51:56.594872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-04-29 16:51:56.683940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.684595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1bbcbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-04-29 16:51:56.684644: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-04-29 16:51:56.684820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.685430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-04-29 16:51:56.685498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:56.685521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-04-29 16:51:56.685545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-04-29 16:51:56.685566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-04-29 16:51:56.685587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-04-29 16:51:56.685608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-04-29 16:51:56.685630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-04-29 16:51:56.685700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.686281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.686792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2020-04-29 16:51:56.686857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-04-29 16:51:56.687842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-04-29 16:51:56.687871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2020-04-29 16:51:56.687882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2020-04-29 16:51:56.688004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.688523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-04-29 16:51:56.689042: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-04-29 16:51:56.689083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12882 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","Traceback (most recent call last):\n","  File \"/tensorflow-1.15.2/python3.6/bin/tflite_convert\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n","    app.run(main=run_main, argv=sys.argv[:1])\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n","    _convert_tf1_model(tflite_flags)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\n","    output_data = converter.convert()\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/lite.py\", line 989, in convert\n","    **converter_kwargs)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/convert.py\", line 412, in toco_convert_graph_def\n","    enable_mlir_converter=enable_mlir_converter)\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\n","    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n","tensorflow.lite.python.convert.ConverterError: See console for info.\n","2020-04-29 16:51:59.715077: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess\n","2020-04-29 16:51:59.721891: F tensorflow/lite/toco/tooling_util.cc:1669] Check failed: input_array_dims[i] == input_array_proto.shape().dims(i) (320 vs. 300)\n","Fatal Python error: Aborted\n","\n","Current thread 0x00007f85433a3780 (most recent call first):\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250 in _run_main\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299 in run\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40 in run\n","  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\n","  File \"/tensorflow-1.15.2/python3.6/bin/toco_from_protos\", line 8 in <module>\n","Aborted (core dumped)\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uTikaJKpK6No","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"b4d2ab89-f514-4f55-d943-dd4a3aa3aac6","executionInfo":{"status":"ok","timestamp":1588186309828,"user_tz":-600,"elapsed":1100,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}}},"source":["'''\n","!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\n","!tflite_convert \\\n","  --output_file='{output_directory}/bus_labels_quantized.tflite' \\\n","  --graph_def_file='{output_directory}/tflite_graph.pb' \\\n","  --inference_type=QUANTIZED_UINT8 \\\n","  --input_arrays='normalized_input_image_tensor' \\\n","  --output_arrays='TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3' \\\n","  --mean_values=128 \\\n","  --std_dev_values=128 \\\n","  --input_shapes=1,300,300,3 \\\n","  --change_concat_input_ranges=false \\\n","  --allow_nudging_weights_to_use_fast_gemm_kernel=true \\\n","  --allow_custom_ops\n","'''"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n!echo \"CONVERTING frozen graph to quantized TF Lite file...\"\\n!tflite_convert   --output_file=\\'{output_directory}/bus_labels_quantized.tflite\\'   --graph_def_file=\\'{output_directory}/tflite_graph.pb\\'   --inference_type=QUANTIZED_UINT8   --input_arrays=\\'normalized_input_image_tensor\\'   --output_arrays=\\'TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\\'   --mean_values=128   --std_dev_values=128   --input_shapes=1,300,300,3   --change_concat_input_ranges=false   --allow_nudging_weights_to_use_fast_gemm_kernel=true   --allow_custom_ops\\n'"]},"metadata":{"tags":[]},"execution_count":101}]},{"cell_type":"code","metadata":{"id":"i_gFUwgtVwzL","colab_type":"code","outputId":"faacb1cb-eb8a-47c2-8816-a8fd949f04f7","executionInfo":{"status":"ok","timestamp":1588186309829,"user_tz":-600,"elapsed":1062,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["print(output_directory)\n","!ls -ltra '{output_directory}'\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")  # this is tflite graph\n","!cp '{label_map_pbtxt_fname}' '{output_directory}'"],"execution_count":102,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/fine_tuned_model\n","total 53932\n","drwx------ 3 root root     4096 Apr 29 16:01 saved_model\n","-rw------- 1 root root     4593 Apr 29 16:01 pipeline.config\n","-rw------- 1 root root       77 Apr 29 16:02 label_map.pbtxt\n","-rw------- 1 root root  1575135 Apr 29 16:50 model.ckpt.meta\n","-rw------- 1 root root    17698 Apr 29 16:50 model.ckpt.index\n","-rw------- 1 root root  8956772 Apr 29 16:50 model.ckpt.data-00000-of-00001\n","-rw------- 1 root root       77 Apr 29 16:50 checkpoint\n","-rw------- 1 root root  9552216 Apr 29 16:50 frozen_inference_graph.pb\n","-rw------- 1 root root 25832584 Apr 29 16:51 tflite_graph.pbtxt\n","-rw------- 1 root root  9280380 Apr 29 16:51 tflite_graph.pb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mz1gX19GlVW7","colab_type":"text"},"source":["# Section 6: Run inference test\n","Test with images in repository `object_detection/data/images/test` directory."]},{"cell_type":"markdown","metadata":{"id":"KvusjJTyt7Ol","colab_type":"text"},"source":["### Reinitialize required variables incase this notebook is not run from the beginning"]},{"cell_type":"code","metadata":{"id":"7GFqouhIU69u","colab_type":"code","outputId":"0f051431-e474-4aa5-8bf1-18750ce12414","executionInfo":{"status":"ok","timestamp":1588186309829,"user_tz":-600,"elapsed":1002,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%matplotlib inline\n","%tensorflow_version 1.x\n","!pip install numpy==1.17.4\n","!pip install --user gast==0.2.2\n","#!pip install imutils"],"execution_count":103,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy==1.17.4 in /usr/local/lib/python3.6/dist-packages (1.17.4)\n","Requirement already satisfied: gast==0.2.2 in /root/.local/lib/python3.6/site-packages (0.2.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2lQhynkoVNwE","colab_type":"code","outputId":"85ed2a6f-9f29-4a20-8053-c1b0d97ee885","executionInfo":{"status":"ok","timestamp":1588186309829,"user_tz":-600,"elapsed":959,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["'''\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","model_dir = '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource'\n","\n","test_record_fname = model_dir + '/Data/annotations/test.record'\n","train_record_fname = model_dir + '/Data/annotations/train.record'\n","label_map_pbtxt_fname = model_dir + '/Data/annotations/label_map.pbtxt'\n","num_classes = 2\n","\n","selected_model = 'ssd_mobilenet_v3_small_coco' #'ssd_mobilenet_v2_quantized'\n","curdate = '2020_04_29'\n","trainedmodel_dir = os.path.join(model_dir, 'trainedmodel', selected_model, curdate)\n","os.makedirs(trainedmodel_dir, exist_ok = True)\n","\n","'''"],"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom google.colab import drive\\ndrive.mount('/content/gdrive')\\nmodel_dir = '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource'\\n\\ntest_record_fname = model_dir + '/Data/annotations/test.record'\\ntrain_record_fname = model_dir + '/Data/annotations/train.record'\\nlabel_map_pbtxt_fname = model_dir + '/Data/annotations/label_map.pbtxt'\\nnum_classes = 2\\n\\nselected_model = 'ssd_mobilenet_v3_small_coco' #'ssd_mobilenet_v2_quantized'\\ncurdate = '2020_04_29'\\ntrainedmodel_dir = os.path.join(model_dir, 'trainedmodel', selected_model, curdate)\\nos.makedirs(trainedmodel_dir, exist_ok = True)\\n\\n\""]},"metadata":{"tags":[]},"execution_count":104}]},{"cell_type":"markdown","metadata":{"id":"BwreaQQHtR8Q","colab_type":"text"},"source":["### Load model & test images for inference"]},{"cell_type":"code","metadata":{"id":"Rpbo5HC0VXuU","colab_type":"code","outputId":"f419a006-32e0-49e8-91e1-cbdd1129750b","executionInfo":{"status":"ok","timestamp":1588186309830,"user_tz":-600,"elapsed":914,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["import os\n","import glob\n","\n","output_directory = trainedmodel_dir+'/fine_tuned_model'\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")  # this is tflite graph\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = pb_fname\n","print(PATH_TO_CKPT)\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n","PATH_TO_TEST_IMAGES_DIR =  os.path.join(model_dir, \"Data/val_cars\")\n","print(PATH_TO_TEST_IMAGES_DIR)\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)"],"execution_count":105,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/trainedmodel/ssd_mobilenet_v3_large_coco/2020_04_29/fine_tuned_model/frozen_inference_graph.pb\n","/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars\n","['/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/1.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/2.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/3.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/4.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/5.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/6.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/7.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/8.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/9.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/10.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/11.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/12.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/13.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/14.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/15.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/16.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/17.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/18.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/19.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/20.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/21.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/22.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/23.jpg']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SXskuNA6vVFw","colab_type":"text"},"source":["### Inference"]},{"cell_type":"code","metadata":{"id":"NR86icuNVb_-","colab_type":"code","outputId":"73b56da2-1aff-4596-9fa8-f60748b719f9","executionInfo":{"status":"ok","timestamp":1588186309832,"user_tz":-600,"elapsed":878,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["%cd '{model_dir}'/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","from object_detection.utils import label_map_util\n","\n","from object_detection.utils import visualization_utils as vis_util\n","\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(\n","    label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","            #print('output_dict',output_dict)\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(\n","                output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict[\n","                'detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","            \n","    return output_dict"],"execution_count":106,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wH28wm2D9NjD","colab_type":"text"},"source":["#### Draw bounding boxes on all test images"]},{"cell_type":"code","metadata":{"id":"oOQLvdrJVfwW","colab_type":"code","outputId":"6b1bf7d1-e1d8-4725-94ac-7ccebbd09bf7","executionInfo":{"status":"ok","timestamp":1588186309832,"user_tz":-600,"elapsed":782,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1oiv6JUOovDYbEJGtnyOlURWYKZ_-wywQ"}},"source":["# running inferences.  This should show images with bounding boxes\n","%matplotlib inline\n","\n","print('Running inferences on %s' % TEST_IMAGE_PATHS)\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    #print('Returned output_dict',output_dict)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=2)\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)\n"],"execution_count":107,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"2DvXEYmuvjcZ","colab_type":"text"},"source":["### Bounding box image crop"]},{"cell_type":"code","metadata":{"id":"dmxqsYEIC1IN","colab_type":"code","colab":{}},"source":["def get_bounding_box_coordinates(image,\n","                               ymin,\n","                               xmin,\n","                               ymax,\n","                               xmax,\n","                               use_normalized_coordinates=True):\n","  \n","  im_width, im_height = image.size\n","  if use_normalized_coordinates:\n","    (left, right, top, bottom) = (int(xmin * im_width), int(xmax * im_width),\n","                                  int(ymin * im_height), int(ymax * im_height))\n","  else:\n","    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n","\n","  return (left, top, right, bottom)  # tuple order matters for cropping\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l8DyMT06xqMl","colab_type":"text"},"source":["### Read Text from cropped image"]},{"cell_type":"markdown","metadata":{"id":"aeWqdmfxxCjf","colab_type":"text"},"source":["#### Use pytesseract for Text Read (Bad)\n","\n","config reference:\n","\n","https://www.pyimagesearch.com/2018/09/17/opencv-ocr-and-text-recognition-with-tesseract/"]},{"cell_type":"code","metadata":{"id":"U6o_cn9UHrnz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"49ea82be-50ff-429c-cfd5-18bcb368e242","executionInfo":{"status":"ok","timestamp":1588186309835,"user_tz":-600,"elapsed":585,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}}},"source":["!apt install tesseract-ocr\n","!apt install libtesseract-dev\n","!pip install pytesseract"],"execution_count":109,"outputs":[{"output_type":"stream","text":["\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 49%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 64%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 81%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n","\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n","\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n","tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libtesseract-dev is already the newest version (4.00~git2288-10f4998a-2).\n","0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.6/dist-packages (0.3.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MfLWKdndp1Dj","colab_type":"code","colab":{}},"source":["import pytesseract\n","from pytesseract import Output\n","import cv2\n","\n","import re\n","\n","def read_image_text(img):\n","  print('image', type(img))\n","  img_np = load_image_into_numpy_array(img)\n","  crop = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n","  \n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(crop)\n","  crop = cv2.GaussianBlur(crop, (5, 5), 0)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(crop)\n","  #_, crop = cv2.threshold(crop, 100, 150, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n","  #plt.figure(figsize=IMAGE_SIZE)\n","  #plt.imshow(crop)\n","\n","  print('1=',pytesseract.image_to_string(crop, config='-l eng --oem 1 --psm 7'))\n","  print('2=',pytesseract.image_to_string(crop, config='--oem 3 --psm 3'))\n","  print('3=',pytesseract.image_to_string(crop))\n","  print('org 3=',pytesseract.image_to_data(crop, output_type=Output.DICT))\n","  print('org 1=',pytesseract.image_to_string(image_np, config='-l eng --oem 1 --psm 7'))\n","  print('org 2=',pytesseract.image_to_string(image_np, config='--oem 3 --psm 3'))\n","  print('org 3=',pytesseract.image_to_string(image_np))\n","  print('org 3=',pytesseract.image_to_data(image_np, output_type=Output.DICT))\n","\n","  custom_config = r'-l eng --oem 1 --psm 7' #r'--oem 3 --psm 3'\n","  text = pytesseract.image_to_string(img, config=custom_config)\n","  print('text from image', text)\n","  return text\n","\n","\n","def read_image_text(img):\n","  (left, top, right, bottom) = (0,25,img.size[0],img.size[1])   \n","  # Grayscale, Gaussian blur, Otsu's threshold\n","  image = img #.crop((left, top, right, bottom))\n","  image = load_image_into_numpy_array(image)\n","  cv2.imwrite(os.path.join(model_dir,'orgcrop.jpg'),image)\n","  image = cv2.resize(image,(0,0),fx=7,fy=7)\n","  plt.imshow(image)\n","  cv2.imwrite(os.path.join(model_dir,'resized.jpg'),image)\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  cv2.imwrite(os.path.join(model_dir,'grayscale.jpg'),gray)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(gray)\n","  blur = cv2.GaussianBlur(gray, (3,3), 0)\n","  cv2.imwrite(os.path.join(model_dir,'GaussianBlur.jpg'),blur)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(blur)\n","  #thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","  #plt.figure(figsize=IMAGE_SIZE)\n","  #plt.imshow(thresh)\n","\n","  # Morph open to remove noise and invert image\n","  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n","  opening = cv2.morphologyEx(blur, cv2.MORPH_OPEN, kernel, iterations=1)\n","  cv2.imwrite(os.path.join(model_dir,'morphologyEx.jpg'),opening)\n","  invert = 255 - opening\n","  cv2.imwrite(os.path.join(model_dir,'invert.jpg'),invert)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(invert)\n","  print('first tiral')\n","  #oem: OCR Engine modes => 1 - Neural nets LSTM engine only\n","  #psm: Page Segmentation Mode ==> \n","  #     3    Fully automatic page segmentation, but no OSD. (Default)\n","  #     6    Assume a single uniform block of text.\n","  #     7    Treat the image as a single text line.\n","  print(pytesseract.image_to_string(invert, lang='eng', config='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789'))\n","  print('second trial',pytesseract.image_to_string(invert, config=\"-c tessedit_char_whitelist=0123456789 -oem 0\"))\n","  print('try different read config')\n","\n","\n","\t# in order to apply Tesseract v4 to OCR text we must supply\n","\t# (1) a language, \n","  # (2) an OEM flag of 1, indicating that the we\n","\t# wish to use the LSTM neural net model for OCR,\n","\t# (3) an OEM value, in this case, 7 which implies that we are\n","\t# treating the ROI as a single line of text\n","  config = (\"-l eng --oem 1 --psm 7\")\n","  text = pytesseract.image_to_string(image, config=config)\n","\n","\t# strip out non-ASCII text so we can draw the text on the image\n","\t# using OpenCV, then draw the text and a bounding box surrounding\n","\t# the text region of the input image\n","  #text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n","  \n","  print('latest article::::',text)\n","  text = pytesseract.image_to_string(image, config=config)\n","\n","  # Perform text extraction\n","  #for i in [1,3,4,5,6,7,8,9,10,11,12,13]:\n","  #  data = pytesseract.image_to_string(invert, lang='eng', config='--psm '+str(i))\n","  #  print('--psm '+str(i), data)\n","  \n","  print('antoher tuning')\n","  retval, image = cv2.threshold(image,200,255, cv2.THRESH_BINARY)\n","  cv2.imwrite(os.path.join(model_dir,'THRESH_BINARY.jpg'),image)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(image)\n","  image = cv2.GaussianBlur(image,(11,11),0)\n","  cv2.imwrite(os.path.join(model_dir,'GaussianBlur2.jpg'),image)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(image)\n","  image = cv2.medianBlur(image,9)\n","  cv2.imwrite(os.path.join(model_dir,'medianBlur.jpg'),image)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(image)\n","  data = pytesseract.image_to_string(image, lang='eng')\n","  print('last trial',pytesseract.image_to_string(image, config=\"-c tessedit_char_whitelist=0123456789 -oem 0\"))\n","  \n","\n","  return data\n","\n","\n","def read_image_text(img, plot=False):\n","  readings = []\n","  config = (\"-l eng --oem 1 --psm 7\")\n","  #(left, top, right, bottom) = (0,25,img.size[0],img.size[1])   \n","  # Grayscale, Gaussian blur, Otsu's threshold\n","  image = img #.crop((left, top, right, bottom))\n","  image = load_image_into_numpy_array(image)\n","  #cv2.imwrite(os.path.join(model_dir,'orgcrop.jpg'),image)\n","  #print('original image',pytesseract.image_to_string(image, config=config))\n","  readings.append(pytesseract.image_to_string(image, config=config))\n","  \n","  image = cv2.resize(image,(0,0),fx=7,fy=7)\n","  if plot:\n","    plt.imshow(image)\n","  #cv2.imwrite(os.path.join(model_dir,'resized.jpg'),image)\n","  #print('rescale image',pytesseract.image_to_string(image, config=config))\n","  readings.append(pytesseract.image_to_string(image, config=config))\n","  \n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  #cv2.imwrite(os.path.join(model_dir,'grayscale.jpg'),gray)\n","  if plot:\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(gray)\n","  #print('gray scale',pytesseract.image_to_string(gray, config=config))\n","  readings.append(pytesseract.image_to_string(gray, config=config))\n","\n","  blur = cv2.GaussianBlur(gray, (3,3), 0)\n","  #cv2.imwrite(os.path.join(model_dir,'GaussianBlur.jpg'),blur)\n","  if plot:\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(blur)\n","  #print('blur',pytesseract.image_to_string(blur, config=config))\n","  readings.append(pytesseract.image_to_string(blur, config=config))\n","\n","  #thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","  #plt.figure(figsize=IMAGE_SIZE)\n","  #plt.imshow(thresh)\n","\n","  # Morph open to remove noise and invert image\n","  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n","  opening = cv2.morphologyEx(blur, cv2.MORPH_OPEN, kernel, iterations=1)\n","  #cv2.imwrite(os.path.join(model_dir,'morphologyEx.jpg'),opening)\n","  #print('morphologyEx',pytesseract.image_to_string(kernel, config=config))\n","  readings.append(pytesseract.image_to_string(kernel, config=config))\n","\n","  invert = 255 - opening\n","  #cv2.imwrite(os.path.join(model_dir,'invert.jpg'),invert)\n","  if plot:\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(invert)\n","  #print('invert',pytesseract.image_to_string(invert, config=config))\n","  readings.append(pytesseract.image_to_string(invert, config=config))\n","  \n","  #print('another tuning')\n","  retval, image = cv2.threshold(image,200,255, cv2.THRESH_BINARY)\n","  #cv2.imwrite(os.path.join(model_dir,'THRESH_BINARY.jpg'),image)\n","  if plot:\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image)\n","  #print('THRESH_BINARY',pytesseract.image_to_string(image, config=config))\n","  readings.append(pytesseract.image_to_string(image, config=config))\n","\n","  image = cv2.GaussianBlur(image,(11,11),0)\n","  #cv2.imwrite(os.path.join(model_dir,'GaussianBlur2.jpg'),image)\n","  if plot:\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image)\n","  #print('GaussianBlur2',pytesseract.image_to_string(image, config=config))\n","  readings.append(pytesseract.image_to_string(image, config=config))\n","\n","  image = cv2.medianBlur(image,9)\n","  #cv2.imwrite(os.path.join(model_dir,'medianBlur.jpg'),image)\n","  if plot:\n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image)\n","  #print('medianBlur',pytesseract.image_to_string(image, config=config))\n","  readings.append(pytesseract.image_to_string(image, config=config))\n","\n","  data = pytesseract.image_to_string(image, lang='eng')\n","  #print('last trial',data)\n","  #print('last trial',pytesseract.image_to_string(image, config=\"-c tessedit_char_whitelist=0123456789 -oem 1\"))\n","  readings.append(pytesseract.image_to_string(image, config=\"-c tessedit_char_whitelist=0123456789 -oem 1\"))\n","  \n","\n","  return readings"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKs90MNgbD9i","colab_type":"code","outputId":"e2c3bfcf-6feb-45e8-dfd6-be38b63e1f01","executionInfo":{"status":"ok","timestamp":1588186309836,"user_tz":-600,"elapsed":483,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# running inferences.  This should show images with bounding boxes\n","%matplotlib inline\n","\n","import pandas\n","\n","consolidated_results = []\n","print('Running inferences on %s' % TEST_IMAGE_PATHS)\n","\n","# Set the default threshold for accepting the bounding box\n","min_score_thresh=.5\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    print('processing image: ',image_path)\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","    # Actual detection\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    \n","    # Read detection Results:\n","    # Predicted boxes for crop coordinates \n","    # box coordinates (ymin, xmin, ymax, xmax) are relative to the image\n","    boxes = output_dict['detection_boxes']\n","    # Scores needed to filtered accepted objects based on threshold\n","    scores = output_dict['detection_scores']\n","\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks'),\n","        use_normalized_coordinates=True,\n","        line_thickness=2)\n","    \n","    #plt.figure(figsize=IMAGE_SIZE)\n","    #plt.imshow(image_np)\n","\n","    # Reset image array for content reading\n","    image_np = load_image_into_numpy_array(image)\n","\n","    for i in range(boxes.shape[0]):\n","        # Filter based on threshold\n","        if scores is None or scores[i] > min_score_thresh:\n","            # boxes[i] is the box which will be drawn\n","            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n","            class_name = category_index[output_dict['detection_classes'][i]]['name']\n","\n","            bounding_box_coordinates = get_bounding_box_coordinates(image, ymin, xmin, ymax, xmax)\n","\n","            # Crop image based on bounding box\n","            cropped_img = image.crop(bounding_box_coordinates)\n","            #plt.figure(figsize=IMAGE_SIZE)\n","            #plt.imshow(cropped_img)\n","\n","            #read text from cropped image\n","            readings = read_image_text(cropped_img)\n","            print('row',[os.path.basename(image_path),class_name,scores[i]]+readings)\n","            consolidated_results.append([os.path.basename(image_path),class_name,scores[i]]+readings)\n","\n","            #print (\"This box is gonna get used\", ymin, xmin, ymax, xmax ,boxes[i], output_dict['detection_classes'][i])\n","            #im_width, im_height = image.size\n","\n","df = pandas.DataFrame(consolidated_results,columns=['image','object','Score','original','resized','grayscale','GaussianBlur','morphologyEx','invert','THRESH_BINARY','GaussianBlur2','medianBlur','numOnly'])\n"],"execution_count":111,"outputs":[{"output_type":"stream","text":["Running inferences on ['/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/1.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/2.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/3.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/4.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/5.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/6.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/7.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/8.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/9.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/10.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/11.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/12.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/13.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/14.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/15.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/16.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/17.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/18.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/19.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/20.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/21.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/22.jpg', '/content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/23.jpg']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/1.jpg\n","row ['1.jpg', 'BusRun', 0.6000578, 'ae ia', 'aa', '44', '44', 'a', 'ses', '44', 'a4', 'a4', '']\n","row ['1.jpg', 'PlateNo', 0.57244426, '10V\"4V)', '| | vs , iA Vv v4 i; V | X', '| 10 TMme v AV)', 'HOV\" 4V)', 'a', '! 10 tans: a e3we', '; | 0 Thee v AVX', 's10V\"4V)', 's10V\"4V)', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/2.jpg\n","row ['2.jpg', 'BusRun', 0.849831, '35', '35', '35', '35', 'a', '35', '35', '', '', '']\n","row ['2.jpg', 'PlateNo', 0.7926589, '', '1 J \\\\ | 4 \\\\ | X', '| | TORIA THE ” | a ie diialin', 'OV 4VX', 'a', 'Deir', '| 10 / 4 ly', '1OV\"4yyX', 'OV 4yX', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/3.jpg\n","row ['3.jpg', 'BusRun', 0.9208525, 'i!', 'hoe TE!', '44', '44', 'a', '44', 'as', 'as', 'as', '']\n","row ['3.jpg', 'PlateNo', 0.73659116, 'UX0%a45', '', '| m™ Q’ 44 5', 'IX ACE', 'a', 'un ACE', '', '', '7 | eee r i', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/4.jpg\n","row ['4.jpg', 'BusRun', 0.8209208, '(pene)', '', 'ae}', 'ae}', 'a', 'ae}', 'i =30 :', '', '', '']\n","row ['4.jpg', 'PlateNo', 0.758515, 'lov*4yx', '10 VY 4VX', '\" 10 THE \"4V)', '’ 10 THE vA4V)', 'a', ', 10 THE oD,', '1OV* 4\\\\ IX', '10V\"4VX', '10V\"4VX', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/5.jpg\n","row ['5.jpg', 'BusRun', 0.62272686, 'ea.', '', 'Bes', 'Bes', 'a', '‘=. ay', '', ', =o', ', =O', '']\n","row ['5.jpg', 'PlateNo', 0.55515176, '[XQ%4q', 'TXQ%4. +', 'TXQ%4. ‘', 'TXQ%4qi', 'a', 'POLE', '', '', '', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/6.jpg\n","row ['6.jpg', 'BusRun', 0.80860984, 'a )', '20', '=', 'i', 'a', 'oe”', '_ |', 'gg 20 |', '@ 20 |', '']\n","row ['6.jpg', 'PlateNo', 0.54354846, 'WUE -455', 'a WUE - 455', 'Oe =', '', 'a', '', 'boos - a a', 'iu is 7 } ad', 'i . i . J', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/7.jpg\n","row ['7.jpg', 'PlateNo', 0.68810695, '', 'UE - ris', 'UE - 45\" S', 'UE - 45\" .', 'a', 'We w a7 ;', ': | 7 - 7', 'a . 7 ; |', '- : 7', '']\n","row ['7.jpg', 'BusRun', 0.66615266, '', 'ib 1 23 ]', '', '', 'a', '', 'A —————— :', '( es 1', '0 —?—— ee', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/8.jpg\n","row ['8.jpg', 'BusRun', 0.90624154, 'eg', '20 :', '\\\\ 28', '\\\\ 28', 'a', 'ea', '¥ _ 28 \\\\', '1 0 \\\\', ', *@ 3', '']\n","row ['8.jpg', 'PlateNo', 0.6401552, '216:Z2BS', 'i216:Z2BS', 'i216:Z2BS', 'i216:Z2BS', 'a', 'i216:Z2BS', 'ee', '', '', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/9.jpg\n","row ['9.jpg', 'BusRun', 0.8933914, 'RO', 'Mao', '- 200', 'LSet)', 'a', 'Sm)', '— 20', '— 20', '— 20', '— 20']\n","row ['9.jpg', 'PlateNo', 0.7926596, 'IPM* 30K', '7 iP  Twe EHUCA rion \"TATE', 'Wiig rive \" 30', 'IPM*30K', 'a', 'RELY', '', '', '; po e | ; fe ‘Y 5 ; <2} an', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/10.jpg\n","row ['10.jpg', 'BusRun', 0.8970483, 'eee', '; an', '\\\\ ae |', '|_|', 'a', 'Ani', '', 'a4 ,', '44 ,', '']\n","row ['10.jpg', 'PlateNo', 0.67654365, '216:ZBS', '216:ZBS', '216:ZBS', '216:ZBS', 'a', '216:ZBS', 'ee', 'ee', 'ee', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/11.jpg\n","row ['11.jpg', 'PlateNo', 0.7926595, 'rpm’ 30k', 'iv. THE oe. grate', '| TORIA THE eas erate', '| TORIA THE ess erate', 'a', '| hides peal. ies Pa Lhe', 'soe: ad 7 Be ae', '- ; a ; a i Bare', '. 7 P 7 ne —J -* ~, ww , :', '']\n","row ['11.jpg', 'BusRun', 0.66255105, 'So', 'Sas', '40', '40', 'a', '8', '— 4', '— 4a', 'eo', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/12.jpg\n","row ['12.jpg', 'PlateNo', 0.79265964, '216-275', '£1626 -', '<16-2B cl', '', 'a', '', 'an', 'an', 'an', '']\n","row ['12.jpg', 'BusRun', 0.7450047, 'Sam', '', 'mz', 'ay', 'a', 'ae', 'in — as 7 .', 'in os ; ~~ .', 'a 3s | ;', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/13.jpg\n","row ['13.jpg', 'PlateNo', 0.6891618, '', \"' OV’ AVA\", \"' \\\\ ) \\\\ if aN \\\\ X\", '10N | \\\\ h', 'a', 'oh 7 “ : i i', '10 a ie i', 'OV ANY', 'OV ANY', '']\n","row ['13.jpg', 'BusRun', 0.68316805, '23', '', '=', 'Ss =', 'a', 'i. ane', '23', '23', '23', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/14.jpg\n","row ['14.jpg', 'BusRun', 0.8927443, 'lad', 'ae', 'any', 'ay', 'a', 'aaa', '7 35 7', '85 7', '35 7', '']\n","row ['14.jpg', 'PlateNo', 0.7926607, 'Pewee', 'Pee', 'Pea', 'Pee', 'a', 'JS JAEI5', 'i a . ; 7 7 | os 7 :', '', '7 a ; 7 7 : | ; ;', 'Pe']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/15.jpg\n","row ['15.jpg', 'BusRun', 0.8259909, '20', 'ae', 'ie;', 'Oe;', 'a', 'ee', 'a.', '', '', 'Zo\\n\\nEE']\n","row ['15.jpg', 'PlateNo', 0.79265994, '', '', 'EARY-FS', 'EARY-FS', 'a', '| JJAE9S', '| ae ; : 7 . . F 7 ; 7 7 7 . 2', 're eels', 'rere r@acns', 'rere r@acns']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/16.jpg\n","row ['16.jpg', 'PlateNo', 0.79265934, '', 'ade E = 4', 'Ne E 4', 'Ee 155', 'a', 'Wien SZ 1 S', 'a .', 'i', 'pI', '']\n","row ['16.jpg', 'BusRun', 0.708358, '— ot', 'ff 32', 'o1', 'o1', 'a', 'o1', '', '', '', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/17.jpg\n","row ['17.jpg', 'BusRun', 0.87041175, 'a', '30 |', '30', '30', 'a', '30', 'ia:', '. _', '. 30 |', '']\n","row ['17.jpg', 'PlateNo', 0.66432196, 'LPM 30K', 'iT THE EOUCATION STATE |', '; IP THe \"39K |', '| IP THE EOUCATION STATE |', 'a', '| Me iil 3 EDUCATION ear Sas: |', '', '', '', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/18.jpg\n","row ['18.jpg', 'BusRun', 0.8812079, '40', '', 'eS', 'pes', 'a', 'aes', '', 'a', '', '']\n","row ['18.jpg', 'PlateNo', 0.79265994, '', '', '] ORts r Fr ‘ AT) On X,', 'Lov Fay y', 'a', 'Weer,', '10 r : . 4| A', 'T i) | iD | IVY', 'JOVYa Vy', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/19.jpg\n","row ['19.jpg', 'BusRun', 0.9069717, '— OL i', '_ ot', 'ol', 'ol', 'a', 'o1', '', '', '', '']\n","row ['19.jpg', 'PlateNo', 0.75123185, '', '', '', 'SHUR', 'a', '', '| ; an a', 'a : | |', '. |', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/20.jpg\n","row ['20.jpg', 'BusRun', 0.7986032, '37', 'fae', '30', '30', 'a', 'i', '— 30°', '30', '30', '']\n","row ['20.jpg', 'PlateNo', 0.79265916, '10 V \"4 V x', '1 OV J | . . a V', 'OV 4Y)', 'OV 4)', 'a', 'Key', 'I( a Tae \"4Vx', '', 'OV 4)', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/21.jpg\n","row ['21.jpg', 'PlateNo', 0.7926599, 'HELE TS', 'EereTy)', 'RYE', 'RYE', 'a', '|; JJA#95)', '', '| a a : ate ; ; ; a , |', 's : “ , . a a : 7 7 . |', 'xe\\n\\n+\\noe']\n","row ['21.jpg', 'BusRun', 0.6160763, '— OL', 'oO1', 'o1', 'O11', 'a', 'eRe', ', CR', ', Cre', '_ Gre', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/22.jpg\n","row ['22.jpg', 'BusRun', 0.83178663, 'i', 'is', 'is', 'is', 'a', 'Pe', 'is', 'is', 'is', '']\n","row ['22.jpg', 'PlateNo', 0.79174113, 'OV\"ayy', 'NOVF4yy', 'NOV ayy', 'HOV ayy', 'a', 'Tinea;', 'I ( 4 a; \"4 f', 'lOVr4Vy', 'lOVr4yy', '']\n","processing image:  /content/gdrive/My Drive/UniMelb/Semester1_2020/Internship/SilverPond/FinalSource/Data/val_cars/23.jpg\n","row ['23.jpg', 'BusRun', 0.88795435, 'aw', 'ea', '30', '30', 'a', '30', '', 'Weem', '390 ,', '390']\n","row ['23.jpg', 'PlateNo', 0.58734953, 'IPM’ 30K', '| 1P. .- 7 wok STATE', '| 1P. » ee y 30K', '| 1P .- Te THtiCcCaAaATion SA TAT', 'a', '| i .- Tuer PTHtiCaATion SA TAT', '| 7 a a : ; ; pa 2 ; - 7 i', '7 : a a a Fy | 2 Ps 7 i', ': 7 s a 7 7 - . 7 ir', '']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0TbJnVkm1-h_","colab_type":"code","outputId":"a1793751-c673-4716-ed46-96f97f645e1a","executionInfo":{"status":"ok","timestamp":1588186309837,"user_tz":-600,"elapsed":413,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>object</th>\n","      <th>Score</th>\n","      <th>original</th>\n","      <th>resized</th>\n","      <th>grayscale</th>\n","      <th>GaussianBlur</th>\n","      <th>morphologyEx</th>\n","      <th>invert</th>\n","      <th>THRESH_BINARY</th>\n","      <th>GaussianBlur2</th>\n","      <th>medianBlur</th>\n","      <th>numOnly</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.600058</td>\n","      <td>ae ia</td>\n","      <td>aa</td>\n","      <td>44</td>\n","      <td>44</td>\n","      <td>a</td>\n","      <td>ses</td>\n","      <td>44</td>\n","      <td>a4</td>\n","      <td>a4</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.572444</td>\n","      <td>10V\"4V)</td>\n","      <td>| | vs , iA Vv v4 i; V | X</td>\n","      <td>| 10 TMme v AV)</td>\n","      <td>HOV\" 4V)</td>\n","      <td>a</td>\n","      <td>! 10 tans: a e3we</td>\n","      <td>; | 0 Thee v AVX</td>\n","      <td>s10V\"4V)</td>\n","      <td>s10V\"4V)</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.849831</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td>a</td>\n","      <td>35</td>\n","      <td>35</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792659</td>\n","      <td></td>\n","      <td>1 J \\ | 4 \\ | X</td>\n","      <td>| | TORIA THE ” | a ie diialin</td>\n","      <td>OV 4VX</td>\n","      <td>a</td>\n","      <td>Deir</td>\n","      <td>| 10 / 4 ly</td>\n","      <td>1OV\"4yyX</td>\n","      <td>OV 4yX</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.920852</td>\n","      <td>i!</td>\n","      <td>hoe TE!</td>\n","      <td>44</td>\n","      <td>44</td>\n","      <td>a</td>\n","      <td>44</td>\n","      <td>as</td>\n","      <td>as</td>\n","      <td>as</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.736591</td>\n","      <td>UX0%a45</td>\n","      <td></td>\n","      <td>| m™ Q’ 44 5</td>\n","      <td>IX ACE</td>\n","      <td>a</td>\n","      <td>un ACE</td>\n","      <td></td>\n","      <td></td>\n","      <td>7 | eee r i</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.820921</td>\n","      <td>(pene)</td>\n","      <td></td>\n","      <td>ae}</td>\n","      <td>ae}</td>\n","      <td>a</td>\n","      <td>ae}</td>\n","      <td>i =30 :</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>4.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.758515</td>\n","      <td>lov*4yx</td>\n","      <td>10 VY 4VX</td>\n","      <td>\" 10 THE \"4V)</td>\n","      <td>’ 10 THE vA4V)</td>\n","      <td>a</td>\n","      <td>, 10 THE oD,</td>\n","      <td>1OV* 4\\ IX</td>\n","      <td>10V\"4VX</td>\n","      <td>10V\"4VX</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.622727</td>\n","      <td>ea.</td>\n","      <td></td>\n","      <td>Bes</td>\n","      <td>Bes</td>\n","      <td>a</td>\n","      <td>‘=. ay</td>\n","      <td></td>\n","      <td>, =o</td>\n","      <td>, =O</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.555152</td>\n","      <td>[XQ%4q</td>\n","      <td>TXQ%4. +</td>\n","      <td>TXQ%4. ‘</td>\n","      <td>TXQ%4qi</td>\n","      <td>a</td>\n","      <td>POLE</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>6.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.808610</td>\n","      <td>a )</td>\n","      <td>20</td>\n","      <td>=</td>\n","      <td>i</td>\n","      <td>a</td>\n","      <td>oe”</td>\n","      <td>_ |</td>\n","      <td>gg 20 |</td>\n","      <td>@ 20 |</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>6.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.543548</td>\n","      <td>WUE -455</td>\n","      <td>a WUE - 455</td>\n","      <td>Oe =</td>\n","      <td></td>\n","      <td>a</td>\n","      <td></td>\n","      <td>boos - a a</td>\n","      <td>iu is 7 } ad</td>\n","      <td>i . i . J</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>7.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.688107</td>\n","      <td></td>\n","      <td>UE - ris</td>\n","      <td>UE - 45\" S</td>\n","      <td>UE - 45\" .</td>\n","      <td>a</td>\n","      <td>We w a7 ;</td>\n","      <td>: | 7 - 7</td>\n","      <td>a . 7 ; |</td>\n","      <td>- : 7</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>7.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.666153</td>\n","      <td></td>\n","      <td>ib 1 23 ]</td>\n","      <td></td>\n","      <td></td>\n","      <td>a</td>\n","      <td></td>\n","      <td>A —————— :</td>\n","      <td>( es 1</td>\n","      <td>0 —?—— ee</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>8.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.906242</td>\n","      <td>eg</td>\n","      <td>20 :</td>\n","      <td>\\ 28</td>\n","      <td>\\ 28</td>\n","      <td>a</td>\n","      <td>ea</td>\n","      <td>¥ _ 28 \\</td>\n","      <td>1 0 \\</td>\n","      <td>, *@ 3</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>8.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.640155</td>\n","      <td>216:Z2BS</td>\n","      <td>i216:Z2BS</td>\n","      <td>i216:Z2BS</td>\n","      <td>i216:Z2BS</td>\n","      <td>a</td>\n","      <td>i216:Z2BS</td>\n","      <td>ee</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>9.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.893391</td>\n","      <td>RO</td>\n","      <td>Mao</td>\n","      <td>- 200</td>\n","      <td>LSet)</td>\n","      <td>a</td>\n","      <td>Sm)</td>\n","      <td>— 20</td>\n","      <td>— 20</td>\n","      <td>— 20</td>\n","      <td>— 20</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>9.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792660</td>\n","      <td>IPM* 30K</td>\n","      <td>7 iP  Twe EHUCA rion \"TATE</td>\n","      <td>Wiig rive \" 30</td>\n","      <td>IPM*30K</td>\n","      <td>a</td>\n","      <td>RELY</td>\n","      <td></td>\n","      <td></td>\n","      <td>; po e | ; fe ‘Y 5 ; &lt;2} an</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>10.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.897048</td>\n","      <td>eee</td>\n","      <td>; an</td>\n","      <td>\\ ae |</td>\n","      <td>|_|</td>\n","      <td>a</td>\n","      <td>Ani</td>\n","      <td></td>\n","      <td>a4 ,</td>\n","      <td>44 ,</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>10.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.676544</td>\n","      <td>216:ZBS</td>\n","      <td>216:ZBS</td>\n","      <td>216:ZBS</td>\n","      <td>216:ZBS</td>\n","      <td>a</td>\n","      <td>216:ZBS</td>\n","      <td>ee</td>\n","      <td>ee</td>\n","      <td>ee</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>11.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792660</td>\n","      <td>rpm’ 30k</td>\n","      <td>iv. THE oe. grate</td>\n","      <td>| TORIA THE eas erate</td>\n","      <td>| TORIA THE ess erate</td>\n","      <td>a</td>\n","      <td>| hides peal. ies Pa Lhe</td>\n","      <td>soe: ad 7 Be ae</td>\n","      <td>- ; a ; a i Bare</td>\n","      <td>. 7 P 7 ne —J -* ~, ww , :</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>11.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.662551</td>\n","      <td>So</td>\n","      <td>Sas</td>\n","      <td>40</td>\n","      <td>40</td>\n","      <td>a</td>\n","      <td>8</td>\n","      <td>— 4</td>\n","      <td>— 4a</td>\n","      <td>eo</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>12.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792660</td>\n","      <td>216-275</td>\n","      <td>£1626 -</td>\n","      <td>&lt;16-2B cl</td>\n","      <td></td>\n","      <td>a</td>\n","      <td></td>\n","      <td>an</td>\n","      <td>an</td>\n","      <td>an</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>12.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.745005</td>\n","      <td>Sam</td>\n","      <td></td>\n","      <td>mz</td>\n","      <td>ay</td>\n","      <td>a</td>\n","      <td>ae</td>\n","      <td>in — as 7 .</td>\n","      <td>in os ; ~~ .</td>\n","      <td>a 3s | ;</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>13.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.689162</td>\n","      <td></td>\n","      <td>' OV’ AVA</td>\n","      <td>' \\ ) \\ if aN \\ X</td>\n","      <td>10N | \\ h</td>\n","      <td>a</td>\n","      <td>oh 7 “ : i i</td>\n","      <td>10 a ie i</td>\n","      <td>OV ANY</td>\n","      <td>OV ANY</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>13.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.683168</td>\n","      <td>23</td>\n","      <td></td>\n","      <td>=</td>\n","      <td>Ss =</td>\n","      <td>a</td>\n","      <td>i. ane</td>\n","      <td>23</td>\n","      <td>23</td>\n","      <td>23</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>14.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.892744</td>\n","      <td>lad</td>\n","      <td>ae</td>\n","      <td>any</td>\n","      <td>ay</td>\n","      <td>a</td>\n","      <td>aaa</td>\n","      <td>7 35 7</td>\n","      <td>85 7</td>\n","      <td>35 7</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>14.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792661</td>\n","      <td>Pewee</td>\n","      <td>Pee</td>\n","      <td>Pea</td>\n","      <td>Pee</td>\n","      <td>a</td>\n","      <td>JS JAEI5</td>\n","      <td>i a . ; 7 7 | os 7 :</td>\n","      <td></td>\n","      <td>7 a ; 7 7 : | ; ;</td>\n","      <td>Pe</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>15.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.825991</td>\n","      <td>20</td>\n","      <td>ae</td>\n","      <td>ie;</td>\n","      <td>Oe;</td>\n","      <td>a</td>\n","      <td>ee</td>\n","      <td>a.</td>\n","      <td></td>\n","      <td></td>\n","      <td>Zo\\n\\nEE</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>15.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792660</td>\n","      <td></td>\n","      <td></td>\n","      <td>EARY-FS</td>\n","      <td>EARY-FS</td>\n","      <td>a</td>\n","      <td>| JJAE9S</td>\n","      <td>| ae ; : 7 . . F 7 ; 7 7 7 . 2</td>\n","      <td>re eels</td>\n","      <td>rere r@acns</td>\n","      <td>rere r@acns</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>16.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792659</td>\n","      <td></td>\n","      <td>ade E = 4</td>\n","      <td>Ne E 4</td>\n","      <td>Ee 155</td>\n","      <td>a</td>\n","      <td>Wien SZ 1 S</td>\n","      <td>a .</td>\n","      <td>i</td>\n","      <td>pI</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>16.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.708358</td>\n","      <td>— ot</td>\n","      <td>ff 32</td>\n","      <td>o1</td>\n","      <td>o1</td>\n","      <td>a</td>\n","      <td>o1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>17.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.870412</td>\n","      <td>a</td>\n","      <td>30 |</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>a</td>\n","      <td>30</td>\n","      <td>ia:</td>\n","      <td>. _</td>\n","      <td>. 30 |</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>17.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.664322</td>\n","      <td>LPM 30K</td>\n","      <td>iT THE EOUCATION STATE |</td>\n","      <td>; IP THe \"39K |</td>\n","      <td>| IP THE EOUCATION STATE |</td>\n","      <td>a</td>\n","      <td>| Me iil 3 EDUCATION ear Sas: |</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>18.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.881208</td>\n","      <td>40</td>\n","      <td></td>\n","      <td>eS</td>\n","      <td>pes</td>\n","      <td>a</td>\n","      <td>aes</td>\n","      <td></td>\n","      <td>a</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>18.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792660</td>\n","      <td></td>\n","      <td></td>\n","      <td>] ORts r Fr ‘ AT) On X,</td>\n","      <td>Lov Fay y</td>\n","      <td>a</td>\n","      <td>Weer,</td>\n","      <td>10 r : . 4| A</td>\n","      <td>T i) | iD | IVY</td>\n","      <td>JOVYa Vy</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>19.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.906972</td>\n","      <td>— OL i</td>\n","      <td>_ ot</td>\n","      <td>ol</td>\n","      <td>ol</td>\n","      <td>a</td>\n","      <td>o1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>19.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.751232</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>SHUR</td>\n","      <td>a</td>\n","      <td></td>\n","      <td>| ; an a</td>\n","      <td>a : | |</td>\n","      <td>. |</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>20.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.798603</td>\n","      <td>37</td>\n","      <td>fae</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>a</td>\n","      <td>i</td>\n","      <td>— 30°</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>20.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792659</td>\n","      <td>10 V \"4 V x</td>\n","      <td>1 OV J | . . a V</td>\n","      <td>OV 4Y)</td>\n","      <td>OV 4)</td>\n","      <td>a</td>\n","      <td>Key</td>\n","      <td>I( a Tae \"4Vx</td>\n","      <td></td>\n","      <td>OV 4)</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>21.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.792660</td>\n","      <td>HELE TS</td>\n","      <td>EereTy)</td>\n","      <td>RYE</td>\n","      <td>RYE</td>\n","      <td>a</td>\n","      <td>|; JJA#95)</td>\n","      <td></td>\n","      <td>| a a : ate ; ; ; a , |</td>\n","      <td>s : “ , . a a : 7 7 . |</td>\n","      <td>xe\\n\\n+\\noe</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>21.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.616076</td>\n","      <td>— OL</td>\n","      <td>oO1</td>\n","      <td>o1</td>\n","      <td>O11</td>\n","      <td>a</td>\n","      <td>eRe</td>\n","      <td>, CR</td>\n","      <td>, Cre</td>\n","      <td>_ Gre</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>22.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.831787</td>\n","      <td>i</td>\n","      <td>is</td>\n","      <td>is</td>\n","      <td>is</td>\n","      <td>a</td>\n","      <td>Pe</td>\n","      <td>is</td>\n","      <td>is</td>\n","      <td>is</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>22.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.791741</td>\n","      <td>OV\"ayy</td>\n","      <td>NOVF4yy</td>\n","      <td>NOV ayy</td>\n","      <td>HOV ayy</td>\n","      <td>a</td>\n","      <td>Tinea;</td>\n","      <td>I ( 4 a; \"4 f</td>\n","      <td>lOVr4Vy</td>\n","      <td>lOVr4yy</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>23.jpg</td>\n","      <td>BusRun</td>\n","      <td>0.887954</td>\n","      <td>aw</td>\n","      <td>ea</td>\n","      <td>30</td>\n","      <td>30</td>\n","      <td>a</td>\n","      <td>30</td>\n","      <td></td>\n","      <td>Weem</td>\n","      <td>390 ,</td>\n","      <td>390</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>23.jpg</td>\n","      <td>PlateNo</td>\n","      <td>0.587350</td>\n","      <td>IPM’ 30K</td>\n","      <td>| 1P. .- 7 wok STATE</td>\n","      <td>| 1P. » ee y 30K</td>\n","      <td>| 1P .- Te THtiCcCaAaATion SA TAT</td>\n","      <td>a</td>\n","      <td>| i .- Tuer PTHtiCaATion SA TAT</td>\n","      <td>| 7 a a : ; ; pa 2 ; - 7 i</td>\n","      <td>7 : a a a Fy | 2 Ps 7 i</td>\n","      <td>: 7 s a 7 7 - . 7 ir</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     image   object  ...                   medianBlur      numOnly\n","0    1.jpg   BusRun  ...                           a4             \n","1    1.jpg  PlateNo  ...                     s10V\"4V)             \n","2    2.jpg   BusRun  ...                                          \n","3    2.jpg  PlateNo  ...                       OV 4yX             \n","4    3.jpg   BusRun  ...                           as             \n","5    3.jpg  PlateNo  ...                  7 | eee r i             \n","6    4.jpg   BusRun  ...                                          \n","7    4.jpg  PlateNo  ...                      10V\"4VX             \n","8    5.jpg   BusRun  ...                         , =O             \n","9    5.jpg  PlateNo  ...                                          \n","10   6.jpg   BusRun  ...                       @ 20 |             \n","11   6.jpg  PlateNo  ...                    i . i . J             \n","12   7.jpg  PlateNo  ...                        - : 7             \n","13   7.jpg   BusRun  ...                    0 —?—— ee             \n","14   8.jpg   BusRun  ...                       , *@ 3             \n","15   8.jpg  PlateNo  ...                                          \n","16   9.jpg   BusRun  ...                         — 20         — 20\n","17   9.jpg  PlateNo  ...  ; po e | ; fe ‘Y 5 ; <2} an             \n","18  10.jpg   BusRun  ...                         44 ,             \n","19  10.jpg  PlateNo  ...                           ee             \n","20  11.jpg  PlateNo  ...   . 7 P 7 ne —J -* ~, ww , :             \n","21  11.jpg   BusRun  ...                           eo             \n","22  12.jpg  PlateNo  ...                           an             \n","23  12.jpg   BusRun  ...                     a 3s | ;             \n","24  13.jpg  PlateNo  ...                       OV ANY             \n","25  13.jpg   BusRun  ...                           23             \n","26  14.jpg   BusRun  ...                         35 7             \n","27  14.jpg  PlateNo  ...            7 a ; 7 7 : | ; ;           Pe\n","28  15.jpg   BusRun  ...                                  Zo\\n\\nEE\n","29  15.jpg  PlateNo  ...                  rere r@acns  rere r@acns\n","30  16.jpg  PlateNo  ...                           pI             \n","31  16.jpg   BusRun  ...                                          \n","32  17.jpg   BusRun  ...                       . 30 |             \n","33  17.jpg  PlateNo  ...                                          \n","34  18.jpg   BusRun  ...                                          \n","35  18.jpg  PlateNo  ...                     JOVYa Vy             \n","36  19.jpg   BusRun  ...                                          \n","37  19.jpg  PlateNo  ...                          . |             \n","38  20.jpg   BusRun  ...                           30             \n","39  20.jpg  PlateNo  ...                        OV 4)             \n","40  21.jpg  PlateNo  ...      s : “ , . a a : 7 7 . |  xe\\n\\n+\\noe\n","41  21.jpg   BusRun  ...                        _ Gre             \n","42  22.jpg   BusRun  ...                           is             \n","43  22.jpg  PlateNo  ...                      lOVr4yy             \n","44  23.jpg   BusRun  ...                        390 ,          390\n","45  23.jpg  PlateNo  ...         : 7 s a 7 7 - . 7 ir             \n","\n","[46 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"BWxid1NX99mi","colab_type":"text"},"source":["####Use Google Vision API\n","\n","https://cloud.google.com/vision/docs/ocr"]},{"cell_type":"code","metadata":{"id":"WM3QMjoJCU6D","colab_type":"code","outputId":"5bde5487-a3ad-4a06-9950-2de579049ed9","executionInfo":{"status":"ok","timestamp":1588186309837,"user_tz":-600,"elapsed":355,"user":{"displayName":"Ghawady Ehmaid","photoUrl":"https://lh5.googleusercontent.com/-BPFWT2oo2Cw/AAAAAAAAAAI/AAAAAAAAAAM/fLD958Ym-60/s64/photo.jpg","userId":"01223438190874405902"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["!pip install --upgrade google-api-python-client"],"execution_count":113,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: google-api-python-client in /usr/local/lib/python3.6/dist-packages (1.8.2)\n","Requirement already satisfied, skipping upgrade: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.16.0)\n","Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.7.2)\n","Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (1.12.0)\n","Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.17.3)\n","Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (3.0.1)\n","Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client) (0.0.3)\n","Requirement already satisfied, skipping upgrade: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (46.1.3)\n","Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (2018.9)\n","Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (2.21.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (3.10.0)\n","Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client) (1.51.0)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (4.0)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.1.1)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.8)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (2020.4.5.1)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client) (2.8)\n","Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gGRQXq8sAkTR","colab_type":"text"},"source":["**Getting a Google API Credential**\n","\n","Visit API console, choose \"Credentials\" on the left-hand menu. Choose \"Create Credentials\" and generate an API key for your application. Ideally restrict it by IP/domain, but for now, just left if blank.\n","Enter the key in this first executable cell:"]},{"cell_type":"code","metadata":{"id":"k8xUhqh1-uhi","colab_type":"code","colab":{}},"source":["import getpass\n","# API Key \n","APIKEY = getpass.getpass()\n","#Need to "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XX1d9huyDWDu","colab_type":"code","colab":{}},"source":["# Import the base64 encoding library.\n","import base64\n","from io import BytesIO\n","\n","# Get base64 encoding of image data\n","def encode_image(image):\n","  buffered = BytesIO()\n","  image.save(buffered, format=\"JPEG\")\n","  img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n","  return img_str\n","\n","# Run Vision API\n","def gvision_detect_text(img):\n","  from googleapiclient.discovery import build\n","  vservice = build('vision', 'v1', developerKey=APIKEY)\n","  request = vservice.images().annotate(body={\n","          'requests': [{\n","                  'image': {\n","                      'content': encode_image(img)\n","                  },\n","                  'features': [{\n","                      'type': 'TEXT_DETECTION',\n","                      'maxResults': 3\n","                  }]\n","              }],\n","          })\n","  responses = request.execute(num_retries=3)\n","  try:\n","    return responses['responses'][0]['textAnnotations'][0]['description']\n","  except:\n","    print('Error occured while fetching results from API')\n","    return ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzp91b7WU17m","colab_type":"code","colab":{}},"source":["# Process text read to fetch only the standard plate number without surrounding text\n","# https://en.wikipedia.org/wiki/Vehicle_registration_plates_of_Australia\n","import re\n","\n","def process_plateno_text(text):\n","  # TODO: Need enhacement, for now only identify two sets of alphanumeric with space\n","  m = re.search('( ?[a-zA-Z0-9]){1,9} ( ?[a-zA-Z0-9]){1,9}', text)\n","  if m:\n","      return m.group()\n","  return ''\n","\n","def process_busrun_text(text):\n","  # Filter only numbers\n","  m = re.search('( ?[0-9]){1,9}', text)\n","  if m:\n","      return m.group()\n","  return ''\n","\n","print('plateno',process_plateno_text('ngscars\\n10V 4VX\\nVIC\\nVICTORIA THE EDUCATION STATE\\n'))\n","print('busrun',process_busrun_text('10V\\n'))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SC6B09UwXyd0","colab_type":"code","colab":{}},"source":["# running inferences.  This should show images with bounding boxes\n","%matplotlib inline\n","\n","import pandas\n","\n","consolidated_results = []\n","print('Running inferences on %s' % TEST_IMAGE_PATHS)\n","\n","# Set the default threshold for accepting the bounding box\n","min_score_thresh=.5\n","\n","for image_path in TEST_IMAGE_PATHS:\n","    print('processing image: ',image_path)\n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    \n","    # Read detection Results:\n","    # Predicted boxes for crop coordinates \n","    # box coordinates (ymin, xmin, ymax, xmax) are relative to the image\n","    boxes = output_dict['detection_boxes']\n","    # Scores needed to filtered accepted objects based on threshold\n","    scores = output_dict['detection_scores']\n","\n","    for i in range(boxes.shape[0]):\n","        # Filter based on threshold\n","        if scores is None or scores[i] > min_score_thresh:\n","            # boxes[i] is the box which will be drawn\n","            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n","            class_name = category_index[output_dict['detection_classes'][i]]['name']\n","\n","            bounding_box_coordinates = get_bounding_box_coordinates(image, ymin, xmin, ymax, xmax)\n","\n","            # Crop image based on bounding box\n","            cropped_img = image.crop(bounding_box_coordinates)\n","            #plt.figure(figsize=IMAGE_SIZE)\n","            #plt.imshow(cropped_img)\n","\n","            #read text from cropped image\n","            readings = gvision_detect_text(cropped_img)\n","            #fine tune reading with appropriate regex\n","            if class_name == 'PlateNo':\n","              readings = process_plateno_text(readings)\n","            elif class_name == 'BusRun':\n","              readings = process_busrun_text(readings)\n","\n","            if readings:\n","              #print('row',[os.path.basename(image_path),class_name,scores[i],readings])\n","              consolidated_results.append([os.path.basename(image_path),class_name,scores[i],readings])\n","            else:\n","              print('nothing returned',readings)\n","\n","            #print (\"This box is gonna get used\", ymin, xmin, ymax, xmax ,boxes[i], output_dict['detection_classes'][i])\n","            #im_width, im_height = image.size\n","\n","df2 = pandas.DataFrame(consolidated_results,columns=['image','object','Score','reading'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2W8t7KkQ9qb","colab_type":"code","colab":{}},"source":["df2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqSFdHQvElks","colab_type":"text"},"source":["# Section 7: Further Enhacements:\n","\n","- Try other object detection pretrained models from the available Zoo list\n","- Adjust Training Hyper parameters\n","- Train with more labeled images \n","- Augment train images (different zooms, rotations, contrast, lighting) (Currently only default is used in the pipeline - horizontal flip & random crop is used)\n","- Explore other multi digit models like SVHN https://arxiv.org/pdf/1312.6082.pdf https://github.com/penny4860/SVHN-deep-digit-detector\n","- Build own multi digit model & train from public dataset (won't be as good as google vision)\n","- Text post processing improvement (to ensure regex covers all standard AUS plates)"]},{"cell_type":"code","metadata":{"id":"eswamFiJLrnM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}